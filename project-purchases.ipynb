{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть данные о том, кто из клиентов именно тот, кто без СМС не купит, а с СМС - купит!\n",
    "\n",
    "Нужно из всех test-клиентов найти и пометить **единицей** тех, кто:\n",
    "\n",
    "* купит только при коммуникации;\n",
    "* не купит без коммуникации.\n",
    "\n",
    "\n",
    "Остальных пометить **нулями**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Содержание:\n",
    "   [<font size=5>1. Предобработка данных</font>](#section_id) <br>\n",
    "       - [1.1 Train.csv и Test.csv](#section_id1.1) <br>\n",
    "       - [1.2 Clients2.csv](#section_id1.2) <br>\n",
    "       - [1.3 Products.csv](#section_id1.3) <br>\n",
    "       - [1.4 train_purch.csv и test_purch.csv](#section_id1.4) <br>\n",
    "   [<font size=5>2. Генерация признаков</font>](#section_id2) <br>\n",
    "       - [2.1 Сумма затрат и количество покупок перед использованием бонусной карты/после](#section_id2.1) <br>\n",
    "       - [2.2 На каждый день недели: количество транзакций, сумма trn_sum_from_iss](#section_id2.2) <br>\n",
    "       - [2.3 На каждый час дня: количество транзакций (без суммы trn_sum_from_iss)](#section_id2.3) <br>\n",
    "       - [2.4 Расчет trn_sum_from_iss суммы при покупке алкоголя/ при покупке собственной продукции. ](#section_id2.4) <br>\n",
    "       - [2.5 Подсчет количества покупок, trn_sum_from_iss которых превосходит определенного значения.](#section_id2.5) <br> \n",
    "       - [2.6 Разность между последним и первым днем покупки.](#section_id2.6) <br>\n",
    "       - [2.7 Признаки, связанные с покупками за все время и за последний месяц](#section_id2.7) <br>\n",
    "       - [2.8 Иные признаки](#section_id2.8) <br> \n",
    "   [<font size=5>3. Анализ созданных признаков</font>](#section_id3) <br>\n",
    "       - [3.1 Поиск признаков, в которых большое количество пропусков](#section_id3.1) <br> \n",
    "       - [3.2 Поиск признаков, которые имеют сильную парную корреляцию](#section_id3.2) <br> \n",
    "       - [3.3 Поиск признаков нулевой важности с помощью предобучения модели LGBM классификатора](#section_id3.3) <br>\n",
    "       - [3.4 Удаление лишних признаков](#section_id3.4) <br>\n",
    "   [<font size=5>4. Обучение моделей</font>](#section_id4) <br>\n",
    "       - [4.1 Построение модели машинного обучения](#section_id4.1) <br>\n",
    "       - [4.2 Функция получения различных метрик](#section_id4.2) <br>\n",
    "       - [4.3 Пространства гиперпараметров, инициализация кросс-валидатора](#section_id4.3) <br>\n",
    "       - [4.4 Функция для вычисления погрешности измерения score модели](#section_id4.4) <br>\n",
    "       - [4.5 Функция для вывода средних значений метрик и их погрешностей при кросс-валидации с текущими параметрами](#section_id4.5) <br>\n",
    "       - [4.6 Функция получения истории поиска оптимальных гиперпараметров для каждого типа модели](#section_id4.6) <br>\n",
    "       - [4.7 Функция поиска лучших значений метрик вместе с их погрешностями, а также параметров, при которых такие результаты достигаются](#section_id4.7) <br>\n",
    "       - [4.8 Функция получения датафрейма со значениями метрик и их погрешностями в зависимости от итерации подбора оптимальных гиперпараметров для заданного типа модели](#section_id4.8) <br>\n",
    "       - [4.9 Функция получения двух датафреймов с результатами подбора гиперпараметров](#section_id4.9) <br>\n",
    "       - [4.10 Получение датафреймов с результатами подбора гиперпараметров](#section_id4.10) <br>\n",
    "       - [4.11 Функция отображения графика зависимости метрики от итерации (с возможностью построения планок погрешностей)](#section_id4.11) <br>\n",
    "       - [4.12 Отображение зависимостей метрик от итерации подбора гиперпараметров](#section_id4.12) <br>\n",
    "       - [4.13 Функция построения гистограмм с погрешностями](#section_id4.13) <br>\n",
    "       - [4.14 Функция добавления в гистограмму лейблов для каждого столбца](#section_id4.14) <br>\n",
    "       - [4.15 Построение гистограмм с погрешностями для каждой метрики для каждого типа модели](#section_id4.15) <br>\n",
    "   [<font size=5>5. Работа с типом модели, показавшим лучшее значение метрики</font>](#section_id5) <br>\n",
    "       - [5.1 Функция получения связки модель + классификатор, для которых лучшее значение метрики](#section_id5.1) <br>\n",
    "       - [5.2 Функция вывода на экран лучшего значения метрики с погрешностью](#section_id5.2) <br>\n",
    "       - [5.3 Функция отображения результатов для лучшей модели относительно данной метрики](#section_id5.3) <br>\n",
    "       - [5.4 Получение результатов для лучшей модели относительно данной метрики](#section_id5.4) <br>\n",
    "          -- [a) Относительно метрики uplift_auc_score](#section_id5.4a) <br>\n",
    "          -- [б) Относительно метрики uplift_at_k](#section_id5.4b) <br>\n",
    "   [<font size=5>6. Предсказания лучших моделей на тестовой выборке</font>](#section_id6) <br>\n",
    "       - [6.1 Функция создания модели с оптимальными значениями гиперпараметров](#section_id6.1) <br>\n",
    "       - [6.2 Функция получения предсказаний модели с оптимальными гиперпараметрами](#section_id6.2) <br>\n",
    "          -- [а) Предсказания для лучшей модели относительно uplift_auc_score](#section_id6.2a) <br>\n",
    "          -- [б) Предсказания для лучшей модели относительно uplift_at_k](#section_id6.2b) <br>\n",
    "       - [6.3 Функция отображения распределения предсказаний для модели](#section_id6.3) <br>\n",
    "       - [6.4 Распределения предсказаний для модели с лучшим uplift_auc_score и uplift_at_k_score](#section_id6.4) <br>\n",
    "   [<font size=5>7. Выводы</font>](#section_id7) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T15:20:30.468370Z",
     "iopub.status.busy": "2023-03-29T15:20:30.467567Z",
     "iopub.status.idle": "2023-03-29T15:20:30.542736Z",
     "shell.execute_reply": "2023-03-29T15:20:30.541444Z",
     "shell.execute_reply.started": "2023-03-29T15:20:30.468205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/final-datasets/train_X.csv\n",
      "/kaggle/input/final-datasets/test_X.csv\n",
      "/kaggle/input/best-results-and-history-of-score-20-iters/best_results_for_20_iter.csv\n",
      "/kaggle/input/best-results-and-history-of-score-20-iters/history_of_scores_for_20_iter.csv\n",
      "/kaggle/input/uplift-shift-23/baseline.csv\n",
      "/kaggle/input/uplift-shift-23/x5-uplift-valid/train_purch/train_purch.csv\n",
      "/kaggle/input/uplift-shift-23/x5-uplift-valid/data/products.csv\n",
      "/kaggle/input/uplift-shift-23/x5-uplift-valid/data/clients2.csv\n",
      "/kaggle/input/uplift-shift-23/x5-uplift-valid/data/train.csv\n",
      "/kaggle/input/uplift-shift-23/x5-uplift-valid/data/test.csv\n",
      "/kaggle/input/uplift-shift-23/x5-uplift-valid/test_purch/test_purch.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:20:33.406110Z",
     "iopub.status.busy": "2023-02-11T13:20:33.405362Z",
     "iopub.status.idle": "2023-02-11T13:20:48.768070Z",
     "shell.execute_reply": "2023-02-11T13:20:48.766712Z",
     "shell.execute_reply.started": "2023-02-11T13:20:33.406050Z"
    }
   },
   "outputs": [],
   "source": [
    "#библиотека sklift\n",
    "!pip install scikit-uplift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:20:48.772059Z",
     "iopub.status.busy": "2023-02-11T13:20:48.771488Z",
     "iopub.status.idle": "2023-02-11T13:21:05.731107Z",
     "shell.execute_reply": "2023-02-11T13:21:05.729904Z",
     "shell.execute_reply.started": "2023-02-11T13:20:48.771999Z"
    }
   },
   "outputs": [],
   "source": [
    "#библиотека Feature Selector\n",
    "!pip install git+https://github.com/WillKoehrsen/feature-selector.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:21:05.733832Z",
     "iopub.status.busy": "2023-02-11T13:21:05.733389Z",
     "iopub.status.idle": "2023-02-11T13:21:08.738169Z",
     "shell.execute_reply": "2023-02-11T13:21:08.736232Z",
     "shell.execute_reply.started": "2023-02-11T13:21:05.733788Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import date, datetime\n",
    "import gc\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold, GridSearchCV, \n",
    "    train_test_split, cross_validate, cross_val_score\n",
    ")\n",
    "\n",
    "from sklift.models import SoloModel, ClassTransformation, TwoModels                                     \n",
    "from sklift.metrics import uplift_at_k, uplift_auc_score, qini_auc_score\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.base import clone\n",
    "\n",
    "from feature_selector import FeatureSelector\n",
    "\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from functools import partial\n",
    "from scipy.stats import sem, t\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Описание данных**\n",
    "\n",
    "> * **train** - набор клиентов для обучения, с указанием `treatment_flg` — была ли совершена коммуникация, `purchased` — была ли совершена покупка\n",
    "> * **test** - список клиентов, для которых необходимо предсказать `target`\n",
    "> * **clients** - информация о клиентах\n",
    "> * **products** -  информация о товарах\n",
    "> * **train_purch** - история покупок train клиентов\n",
    "> * **test_purch** - история покупок test клиентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T15:21:00.485557Z",
     "iopub.status.busy": "2023-03-29T15:21:00.484753Z",
     "iopub.status.idle": "2023-03-29T15:21:00.496247Z",
     "shell.execute_reply": "2023-03-29T15:21:00.494718Z",
     "shell.execute_reply.started": "2023-03-29T15:21:00.485503Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_info(df):\n",
    "    'Выводит первичный обзор датафрейма'\n",
    "    \n",
    "    print('Обзор таблицы:')\n",
    "    display(df.head(5))\n",
    "    print('*'*100)\n",
    "    print('Информация о таблице:')\n",
    "    df.info()\n",
    "    print('*'*100)\n",
    "    print('Дополнительные характеристики данных в таблице:')\n",
    "    display(df.describe())\n",
    "    display(df.describe(include='object'))\n",
    "    print('*'*100)\n",
    "    print('Кол-во строк и столбцов:')\n",
    "    print(df.shape)\n",
    "    print('*'*100)\n",
    "    print('Кол-во пропусков:')\n",
    "    display(df.isna().mean())\n",
    "    print('*'*100)\n",
    "    print('Кол-во дубликатов:')\n",
    "    print(df.duplicated().sum())\n",
    "    \n",
    "    \n",
    "def return_memory(data):\n",
    "  'Возвращает объем использованной памяти'\n",
    "  return print(f'{round(data.memory_usage().sum() / 1024**2)} Mb')    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA <a id='section_id'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T15:30:46.533996Z",
     "iopub.status.busy": "2023-03-29T15:30:46.532686Z",
     "iopub.status.idle": "2023-03-29T15:30:46.539382Z",
     "shell.execute_reply": "2023-03-29T15:30:46.538316Z",
     "shell.execute_reply.started": "2023-03-29T15:30:46.533949Z"
    }
   },
   "outputs": [],
   "source": [
    "dirpath = '/kaggle/input/uplift-shift-23/'\n",
    "train_path, test_path = 'x5-uplift-valid/data/train.csv', 'x5-uplift-valid/data/test.csv'\n",
    "clients_path, products_path = 'x5-uplift-valid/data/clients2.csv', 'x5-uplift-valid/data/products.csv'\n",
    "train_purch_path = 'x5-uplift-valid/train_purch/train_purch.csv'\n",
    "test_purch_path = 'x5-uplift-valid/test_purch/test_purch.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>train.csv и test.csv</h2>\n",
    "<a id='section_id1.1'></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T15:25:36.342806Z",
     "iopub.status.busy": "2023-03-29T15:25:36.342232Z",
     "iopub.status.idle": "2023-03-29T15:25:36.517497Z",
     "shell.execute_reply": "2023-03-29T15:25:36.516522Z",
     "shell.execute_reply.started": "2023-03-29T15:25:36.342762Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(os.path.join(dirpath,train_path))\n",
    "df_test = pd.read_csv(os.path.join(dirpath,test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T15:24:29.674088Z",
     "iopub.status.busy": "2023-03-29T15:24:29.673629Z",
     "iopub.status.idle": "2023-03-29T15:24:29.877599Z",
     "shell.execute_reply": "2023-03-29T15:24:29.876329Z",
     "shell.execute_reply.started": "2023-03-29T15:24:29.674048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обзор таблицы:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>treatment_flg</th>\n",
       "      <th>purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ad6561e2d8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7c1ccbf93f</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b58fadcab6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e99e6fabb9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27fb6f8520</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    client_id  treatment_flg  purchased\n",
       "0  ad6561e2d8              1          1\n",
       "1  7c1ccbf93f              1          1\n",
       "2  b58fadcab6              1          1\n",
       "3  e99e6fabb9              0          0\n",
       "4  27fb6f8520              1          1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Информация о таблице:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 140027 entries, 0 to 140026\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   client_id      140027 non-null  object\n",
      " 1   treatment_flg  140027 non-null  int64 \n",
      " 2   purchased      140027 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.2+ MB\n",
      "****************************************************************************************************\n",
      "Дополнительные характеристики данных в таблице:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treatment_flg</th>\n",
       "      <th>purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>140027.000000</td>\n",
       "      <td>140027.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500325</td>\n",
       "      <td>0.619630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500002</td>\n",
       "      <td>0.485479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       treatment_flg      purchased\n",
       "count  140027.000000  140027.000000\n",
       "mean        0.500325       0.619630\n",
       "std         0.500002       0.485479\n",
       "min         0.000000       0.000000\n",
       "25%         0.000000       0.000000\n",
       "50%         1.000000       1.000000\n",
       "75%         1.000000       1.000000\n",
       "max         1.000000       1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>140027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>140027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ad6561e2d8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         client_id\n",
       "count       140027\n",
       "unique      140027\n",
       "top     ad6561e2d8\n",
       "freq             1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Кол-во строк и столбцов:\n",
      "(140027, 3)\n",
      "****************************************************************************************************\n",
      "Кол-во пропусков:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "client_id        0.0\n",
       "treatment_flg    0.0\n",
       "purchased        0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Кол-во дубликатов:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "get_info(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:21:09.345852Z",
     "iopub.status.busy": "2023-02-11T13:21:09.345339Z",
     "iopub.status.idle": "2023-02-11T13:21:09.534195Z",
     "shell.execute_reply": "2023-02-11T13:21:09.532152Z",
     "shell.execute_reply.started": "2023-02-11T13:21:09.345815Z"
    }
   },
   "outputs": [],
   "source": [
    "get_info(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Описание переменных</h2>\n",
    "\n",
    "**client_id** - уникальный идентификатор покупателя<br>\n",
    "**treatment_flg** - факт взаимодействия с покупателем<br>\n",
    "**purchased** - факт покупки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Мысли**:\n",
    "* В трейне нет явного таргета, который нам нужен\n",
    "* По признаку `client_id` будем мержить данные между собой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:21:09.536855Z",
     "iopub.status.busy": "2023-02-11T13:21:09.536363Z",
     "iopub.status.idle": "2023-02-11T13:21:09.818921Z",
     "shell.execute_reply": "2023-02-11T13:21:09.817477Z",
     "shell.execute_reply.started": "2023-02-11T13:21:09.536817Z"
    }
   },
   "outputs": [],
   "source": [
    "#Cохранение используемых client_id. В других файлах могут использоваться другие id.\n",
    "\n",
    "clients = np.unique(np.concatenate((df_train['client_id'].to_numpy(), df_test['client_id'].to_numpy())))\n",
    "len(clients) == df_train.shape[0] + df_test.shape[0] #проверка\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:21:09.823975Z",
     "iopub.status.busy": "2023-02-11T13:21:09.823364Z",
     "iopub.status.idle": "2023-02-11T13:21:10.292365Z",
     "shell.execute_reply": "2023-02-11T13:21:10.290677Z",
     "shell.execute_reply.started": "2023-02-11T13:21:09.823934Z"
    }
   },
   "outputs": [],
   "source": [
    "#посмотрим на распределение treatment_flg и purchased\n",
    "X = df_train.groupby([\"treatment_flg\", \"purchased\"], as_index=False).size() \\\n",
    "  .assign(ratio = lambda x: x[\"size\"] / x[\"size\"].sum() ) \n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 5))\n",
    "ax=sns.barplot(data=X, x='purchased', y='ratio', hue='treatment_flg')\n",
    "ax.set(title='Распределение treatment_flg и purchased')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Мысли**:\n",
    "\n",
    "* При одном и том же значении purchased доля людей, с которыми была совершена коммуникация примерно равна доле людей, с которыми не происходило коммуникации.\n",
    "* Совершивших покупку людей больше, чем тех, кто ее не совершал."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>clients2.csv</h2>\n",
    "<a id='section_id1.2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T15:27:13.618073Z",
     "iopub.status.busy": "2023-03-29T15:27:13.617649Z",
     "iopub.status.idle": "2023-03-29T15:27:14.363309Z",
     "shell.execute_reply": "2023-03-29T15:27:14.361742Z",
     "shell.execute_reply.started": "2023-03-29T15:27:13.618037Z"
    }
   },
   "outputs": [],
   "source": [
    "df_clients = pd.read_csv(os.path.join(dirpath,clients_path),\n",
    "                         parse_dates=[\"first_issue_date\", \"first_redeem_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T15:27:20.947530Z",
     "iopub.status.busy": "2023-03-29T15:27:20.947021Z",
     "iopub.status.idle": "2023-03-29T15:27:21.360154Z",
     "shell.execute_reply": "2023-03-29T15:27:21.358951Z",
     "shell.execute_reply.started": "2023-03-29T15:27:20.947493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обзор таблицы:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>client_id.1</th>\n",
       "      <th>first_issue_date</th>\n",
       "      <th>first_redeem_date</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000012768d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-05 15:40:48</td>\n",
       "      <td>2018-01-04 19:30:07</td>\n",
       "      <td>45</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000036f903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-04-10 13:54:23</td>\n",
       "      <td>2017-04-23 12:37:56</td>\n",
       "      <td>72</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00010925a5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-07-24 16:21:29</td>\n",
       "      <td>2018-09-14 16:12:49</td>\n",
       "      <td>83</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001f552b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-06-30 19:20:38</td>\n",
       "      <td>2018-08-28 12:59:45</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00020e7b18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-11-27 11:41:45</td>\n",
       "      <td>2018-01-10 17:50:05</td>\n",
       "      <td>73</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    client_id  client_id.1    first_issue_date   first_redeem_date  age gender\n",
       "0  000012768d          NaN 2017-08-05 15:40:48 2018-01-04 19:30:07   45      U\n",
       "1  000036f903          NaN 2017-04-10 13:54:23 2017-04-23 12:37:56   72      F\n",
       "2  00010925a5          NaN 2018-07-24 16:21:29 2018-09-14 16:12:49   83      U\n",
       "3  0001f552b0          NaN 2017-06-30 19:20:38 2018-08-28 12:59:45   33      F\n",
       "4  00020e7b18          NaN 2017-11-27 11:41:45 2018-01-10 17:50:05   73      U"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Информация о таблице:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200039 entries, 0 to 200038\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count   Dtype         \n",
      "---  ------             --------------   -----         \n",
      " 0   client_id          200039 non-null  object        \n",
      " 1   client_id.1        0 non-null       float64       \n",
      " 2   first_issue_date   200039 non-null  datetime64[ns]\n",
      " 3   first_redeem_date  182493 non-null  datetime64[ns]\n",
      " 4   age                200039 non-null  int64         \n",
      " 5   gender             200039 non-null  object        \n",
      "dtypes: datetime64[ns](2), float64(1), int64(1), object(2)\n",
      "memory usage: 9.2+ MB\n",
      "****************************************************************************************************\n",
      "Дополнительные характеристики данных в таблице:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id.1</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>200039.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>46.417329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>49.532475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-7491.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>59.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1852.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       client_id.1            age\n",
       "count          0.0  200039.000000\n",
       "mean           NaN      46.417329\n",
       "std            NaN      49.532475\n",
       "min            NaN   -7491.000000\n",
       "25%            NaN      34.000000\n",
       "50%            NaN      45.000000\n",
       "75%            NaN      59.000000\n",
       "max            NaN    1852.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200039</td>\n",
       "      <td>200039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>200039</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>000012768d</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>92832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         client_id  gender\n",
       "count       200039  200039\n",
       "unique      200039       3\n",
       "top     000012768d       U\n",
       "freq             1   92832"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Кол-во строк и столбцов:\n",
      "(200039, 6)\n",
      "****************************************************************************************************\n",
      "Кол-во пропусков:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "client_id            0.000000\n",
       "client_id.1          1.000000\n",
       "first_issue_date     0.000000\n",
       "first_redeem_date    0.087713\n",
       "age                  0.000000\n",
       "gender               0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Кол-во дубликатов:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "get_info(df_clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Описание переменных</h2>\n",
    "\n",
    "**client_id** - уникальный идентификатор покупателя<br>\n",
    "**client_id.1** - неизвестный столбец<br>\n",
    "**first_issue_date** - дата первой покупки<br>\n",
    "**first_redeem_date** - дата первого использования бонусных баллов<br>\n",
    "**age** - возраст покупателя<br>\n",
    "**gender** - пол покупателя"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Мысли**:\n",
    "\n",
    "* Появились первые пропуски - в признаке `first_redeem_date`.  Можно заполнить пустые ячейки следующим днем после последнего дня в first_redeem_date - 21 ноября 2019. Также полностью незаполнен столбец client_id.1 (его надо совсем убрать)\n",
    "* Имеются заведомо ложные значения возраста: max=1852, min=-7491?! Стоит оставить возраста от 14 лет до 100 лет (вполне разумные значения), а остальные значения заменить, например, на -2 (если возраст >100 лет) и -3 (если возраст < 14 лет). Предварительно построить график распределения возраста клиентов (возможно вскроются причины несостыковки с логикой)\n",
    "* Посмотреть сколько мужчин, женщин и не отметивших пол клиентов\n",
    "* Посмотреть по дням сколько людей совершали свою первую покупку и сколько людей впервые использовали бонусные баллы (построить графики)\n",
    "* Создать временные признаки, связанные с `first_redeem_date` и `first_issue_date`: день недели, месяц, дата события (количество дней с 1 января 1970г)\n",
    "* Можно создать признак - разницу между `first_redeem_date` и `first_issue_date`\n",
    "* Категориальную переменную `gender`, которая принимает значения M, F, U преобразовать в числовую переменную, принимающую значения 0 - M, 1 - F, 2 - U\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:21:11.592176Z",
     "iopub.status.busy": "2023-02-11T13:21:11.591687Z",
     "iopub.status.idle": "2023-02-11T13:21:11.846815Z",
     "shell.execute_reply": "2023-02-11T13:21:11.845418Z",
     "shell.execute_reply.started": "2023-02-11T13:21:11.592129Z"
    }
   },
   "outputs": [],
   "source": [
    "#посмотрим на распределение возраста клиентов\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 5))\n",
    "ax=sns.boxplot(x='age',data=df_clients)\n",
    "ax.set(xlabel='Возраст клиентов', title='Распределение возраста клиентов')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:21:11.848563Z",
     "iopub.status.busy": "2023-02-11T13:21:11.848191Z",
     "iopub.status.idle": "2023-02-11T13:21:13.027921Z",
     "shell.execute_reply": "2023-02-11T13:21:13.026602Z",
     "shell.execute_reply.started": "2023-02-11T13:21:11.848514Z"
    }
   },
   "outputs": [],
   "source": [
    "#посмотрим на распределение после отсечения заведомо ложных возрастов\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 5))\n",
    "ax=sns.histplot(x='age',\n",
    "             data=df_clients[(df_clients.age<=100) & (df_clients.age>=14)], \n",
    "             bins=87, hue='gender', multiple='stack')\n",
    "ax.set(xlabel='Возраст клиентов', ylabel='Количество',\n",
    "      title='Распределение возраста клиентов, возраст которых от 14 до 100 лет')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:21:13.030880Z",
     "iopub.status.busy": "2023-02-11T13:21:13.029709Z",
     "iopub.status.idle": "2023-02-11T13:21:13.415213Z",
     "shell.execute_reply": "2023-02-11T13:21:13.413923Z",
     "shell.execute_reply.started": "2023-02-11T13:21:13.030824Z"
    }
   },
   "outputs": [],
   "source": [
    "#посмотрим на распределение по полу\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 5))\n",
    "\n",
    "sns.histplot(x='gender', data=df_clients)\n",
    "ax.set(xlabel='пол', ylabel='Количество',\n",
    "      title='Распределение клиентов по полу')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:21:13.417403Z",
     "iopub.status.busy": "2023-02-11T13:21:13.417014Z",
     "iopub.status.idle": "2023-02-11T13:21:14.309323Z",
     "shell.execute_reply": "2023-02-11T13:21:14.307958Z",
     "shell.execute_reply.started": "2023-02-11T13:21:13.417367Z"
    }
   },
   "outputs": [],
   "source": [
    "#графики распределений количества людей, у которых общая дата первой покупки, и \n",
    "#первого использования бонусных баллов\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 5))\n",
    "clients_date = df_clients.assign(first_issue_date=lambda x: x[\"first_issue_date\"].dt.date)\n",
    "clients_date_count = clients_date.groupby(['first_issue_date'],as_index=False)['client_id'].count()\n",
    "clients_date_count.rename(columns={\"client_id\": \"count\"},inplace=True)\n",
    "sns.lineplot(data=clients_date_count, x=\"first_issue_date\", y=\"count\",\n",
    "             label=\"first_issue_date\", ax=ax)\n",
    "\n",
    "clients_date = df_clients.assign(first_redeem_date=lambda x: x[\"first_redeem_date\"].dt.date)\n",
    "clients_date_count = clients_date.groupby(['first_redeem_date'],as_index=False)['client_id'].count()\n",
    "clients_date_count.rename(columns={\"client_id\": \"count\"},inplace=True)\n",
    "sns.lineplot(data=clients_date_count, x=\"first_redeem_date\", y=\"count\",\n",
    "             label=\"first_redeem_date\", ax=ax)\n",
    "\n",
    "ax.set(xlabel=\"Дата\", ylabel=\"Количество\")\n",
    "plt.xticks(rotation= 90)\n",
    "\n",
    "del clients_date, clients_date_count\n",
    "\n",
    "#видим, что имеются резкие пики для first_redeem_date под новый год и в марте-апреле\n",
    "#2019 года"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:21:14.311375Z",
     "iopub.status.busy": "2023-02-11T13:21:14.310994Z",
     "iopub.status.idle": "2023-02-11T13:21:14.401418Z",
     "shell.execute_reply": "2023-02-11T13:21:14.400381Z",
     "shell.execute_reply.started": "2023-02-11T13:21:14.311339Z"
    }
   },
   "outputs": [],
   "source": [
    "#client_id.1 - все ячейки не заполнены => удаляем\n",
    "print(f'Уникальные client_id.1: {df_clients[\"client_id.1\"].unique()}\\n')\n",
    "df_clients.drop(columns=['client_id.1'],inplace=True)\n",
    "\n",
    "#first_issue_date - выведем первую и последнюю дату\n",
    "print(f'first_issue_date: min - {df_clients[\"first_issue_date\"].min()}, max - {df_clients[\"first_issue_date\"].max()}')\n",
    "#first_redeem_date - выведем первую и последнюю дату\n",
    "print(f'first_redeem_date: min - {df_clients[\"first_redeem_date\"].min()}, max - {df_clients[\"first_redeem_date\"].max()}\\n')\n",
    "\n",
    "#заполнение пропусков\n",
    "df_clients['first_redeem_date'] = df_clients['first_redeem_date'].fillna(datetime(2019, 11, 21, 0, 0))\n",
    "\n",
    "#age - минимальный и максимальный\n",
    "print(f'Age: min - {min(df_clients[\"age\"])}, max - {max(df_clients[\"age\"])}')\n",
    "# -7491 и 1852??! - сделаем адекватную оценку возраста и посмотрим на выбросы\n",
    "print(f'Кол-во людей возраст которых больше 100 лет: {(df_clients[\"age\"]>100).sum()}. Меньше 14 лет: {(df_clients[\"age\"]<14).sum()}\\n')\n",
    "\n",
    "#gender - сколько мужчин, женщин и не указавших пол\n",
    "display(df_clients.groupby('gender').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:21:14.403418Z",
     "iopub.status.busy": "2023-02-11T13:21:14.403040Z",
     "iopub.status.idle": "2023-02-11T13:21:14.572444Z",
     "shell.execute_reply": "2023-02-11T13:21:14.570671Z",
     "shell.execute_reply.started": "2023-02-11T13:21:14.403383Z"
    }
   },
   "outputs": [],
   "source": [
    "#доп фичи времени по first_issue_date\n",
    "df_clients['first_issue_date_weekday'] = df_clients['first_issue_date'].dt.weekday.astype('object')\n",
    "df_clients['first_issue_date_month'] = df_clients['first_issue_date'].dt.month.astype('object')\n",
    "df_clients['first_issue_time'] = (df_clients['first_issue_date'] - pd.Timestamp('1970-01-01'))//pd.Timedelta('1d')\n",
    "#first_issue_time - количество дней с 1 января 1970 года\n",
    "\n",
    "\n",
    "#доп фичи времени по first_redeem_date\n",
    "df_clients['first_redeem_date_weekday'] = df_clients['first_redeem_date'].dt.weekday.astype('object')\n",
    "df_clients['first_redeem_date_month'] = df_clients['first_redeem_date'].dt.month.astype('object')\n",
    "df_clients['first_redeem_time'] = (df_clients['first_redeem_date'] - pd.Timestamp('1970-01-01'))//pd.Timedelta('1d')\n",
    "#first_redeem_time - количество дней с 1 января 1970 года\n",
    "df_clients['diff'] = df_clients['first_redeem_time']-df_clients['first_issue_time']\n",
    "\n",
    "\n",
    "#преобразование категориальной переменной\n",
    "df_clients['gender']=df_clients['gender'].map({'M': 0, 'F': 1, 'U': 2})\n",
    "\n",
    "#df_clients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:21:14.575331Z",
     "iopub.status.busy": "2023-02-11T13:21:14.574710Z",
     "iopub.status.idle": "2023-02-11T13:21:14.586565Z",
     "shell.execute_reply": "2023-02-11T13:21:14.584626Z",
     "shell.execute_reply.started": "2023-02-11T13:21:14.575261Z"
    }
   },
   "outputs": [],
   "source": [
    "def replace_age(df_clients):\n",
    "    'Если возраст больше 100 лет, то записываю -2'\n",
    "    'Если возраст меньше 14 лет, то записываю -3'\n",
    "    age = df_clients['age'].values\n",
    "    age[age >100] = -2\n",
    "    age[age < 14] = -3\n",
    "    df_clients['age']=age\n",
    "\n",
    "    return df_clients\n",
    "\n",
    "\n",
    "df_clients = replace_age(df_clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>products.csv</h2>\n",
    "<a id='section_id1.3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T15:29:05.594719Z",
     "iopub.status.busy": "2023-03-29T15:29:05.594244Z",
     "iopub.status.idle": "2023-03-29T15:29:05.754392Z",
     "shell.execute_reply": "2023-03-29T15:29:05.753344Z",
     "shell.execute_reply.started": "2023-03-29T15:29:05.594680Z"
    }
   },
   "outputs": [],
   "source": [
    "df_products = pd.read_csv(os.path.join(dirpath,products_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T15:29:08.900787Z",
     "iopub.status.busy": "2023-03-29T15:29:08.900371Z",
     "iopub.status.idle": "2023-03-29T15:29:09.086175Z",
     "shell.execute_reply": "2023-03-29T15:29:09.085102Z",
     "shell.execute_reply.started": "2023-03-29T15:29:08.900752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обзор таблицы:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>level_1</th>\n",
       "      <th>level_2</th>\n",
       "      <th>level_3</th>\n",
       "      <th>level_4</th>\n",
       "      <th>segment_id</th>\n",
       "      <th>brand_id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>netto</th>\n",
       "      <th>is_own_trademark</th>\n",
       "      <th>is_alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0003020d3c</td>\n",
       "      <td>c3d3a8e8c6</td>\n",
       "      <td>c2a3ea8d5e</td>\n",
       "      <td>b7cda0ec0c</td>\n",
       "      <td>6376f2a852</td>\n",
       "      <td>123.0</td>\n",
       "      <td>394a54a7c1</td>\n",
       "      <td>9eaff48661</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0003870676</td>\n",
       "      <td>e344ab2e71</td>\n",
       "      <td>52f13dac0c</td>\n",
       "      <td>d3cfe81323</td>\n",
       "      <td>6dc544533f</td>\n",
       "      <td>105.0</td>\n",
       "      <td>acd3dd483f</td>\n",
       "      <td>10486c3cf0</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003ceaf69</td>\n",
       "      <td>c3d3a8e8c6</td>\n",
       "      <td>f2333c90fb</td>\n",
       "      <td>419bc5b424</td>\n",
       "      <td>f6148afbc0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>f597581079</td>\n",
       "      <td>764e660dda</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000701e093</td>\n",
       "      <td>ec62ce61e3</td>\n",
       "      <td>4202626fcb</td>\n",
       "      <td>88a515c084</td>\n",
       "      <td>48cf3d488f</td>\n",
       "      <td>172.0</td>\n",
       "      <td>54a90fe769</td>\n",
       "      <td>03c2d70bad</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0007149564</td>\n",
       "      <td>e344ab2e71</td>\n",
       "      <td>52f13dac0c</td>\n",
       "      <td>d3cfe81323</td>\n",
       "      <td>6dc544533f</td>\n",
       "      <td>105.0</td>\n",
       "      <td>63417fe1f3</td>\n",
       "      <td>f329130198</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id     level_1     level_2     level_3     level_4  segment_id  \\\n",
       "0  0003020d3c  c3d3a8e8c6  c2a3ea8d5e  b7cda0ec0c  6376f2a852       123.0   \n",
       "1  0003870676  e344ab2e71  52f13dac0c  d3cfe81323  6dc544533f       105.0   \n",
       "2  0003ceaf69  c3d3a8e8c6  f2333c90fb  419bc5b424  f6148afbc0       271.0   \n",
       "3  000701e093  ec62ce61e3  4202626fcb  88a515c084  48cf3d488f       172.0   \n",
       "4  0007149564  e344ab2e71  52f13dac0c  d3cfe81323  6dc544533f       105.0   \n",
       "\n",
       "     brand_id   vendor_id  netto  is_own_trademark  is_alcohol  \n",
       "0  394a54a7c1  9eaff48661  0.400                 0           0  \n",
       "1  acd3dd483f  10486c3cf0  0.680                 0           0  \n",
       "2  f597581079  764e660dda  0.500                 0           0  \n",
       "3  54a90fe769  03c2d70bad  0.112                 0           0  \n",
       "4  63417fe1f3  f329130198  0.600                 0           0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Информация о таблице:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43038 entries, 0 to 43037\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   product_id        43038 non-null  object \n",
      " 1   level_1           43035 non-null  object \n",
      " 2   level_2           43035 non-null  object \n",
      " 3   level_3           43035 non-null  object \n",
      " 4   level_4           43035 non-null  object \n",
      " 5   segment_id        41466 non-null  float64\n",
      " 6   brand_id          37838 non-null  object \n",
      " 7   vendor_id         43004 non-null  object \n",
      " 8   netto             43035 non-null  float64\n",
      " 9   is_own_trademark  43038 non-null  int64  \n",
      " 10  is_alcohol        43038 non-null  int64  \n",
      "dtypes: float64(2), int64(2), object(7)\n",
      "memory usage: 3.6+ MB\n",
      "****************************************************************************************************\n",
      "Дополнительные характеристики данных в таблице:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_id</th>\n",
       "      <th>netto</th>\n",
       "      <th>is_own_trademark</th>\n",
       "      <th>is_alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>41466.000000</td>\n",
       "      <td>43035.000000</td>\n",
       "      <td>43038.000000</td>\n",
       "      <td>43038.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>153.918222</td>\n",
       "      <td>0.536966</td>\n",
       "      <td>0.035178</td>\n",
       "      <td>0.055602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>82.271376</td>\n",
       "      <td>8.274367</td>\n",
       "      <td>0.184232</td>\n",
       "      <td>0.229154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>105.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>148.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>214.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>321.000000</td>\n",
       "      <td>1150.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         segment_id         netto  is_own_trademark    is_alcohol\n",
       "count  41466.000000  43035.000000      43038.000000  43038.000000\n",
       "mean     153.918222      0.536966          0.035178      0.055602\n",
       "std       82.271376      8.274367          0.184232      0.229154\n",
       "min        1.000000      0.000000          0.000000      0.000000\n",
       "25%      105.000000      0.150000          0.000000      0.000000\n",
       "50%      148.000000      0.300000          0.000000      0.000000\n",
       "75%      214.000000      0.500000          0.000000      0.000000\n",
       "max      321.000000   1150.000000          1.000000      1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>level_1</th>\n",
       "      <th>level_2</th>\n",
       "      <th>level_3</th>\n",
       "      <th>level_4</th>\n",
       "      <th>brand_id</th>\n",
       "      <th>vendor_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>43038</td>\n",
       "      <td>43035</td>\n",
       "      <td>43035</td>\n",
       "      <td>43035</td>\n",
       "      <td>43035</td>\n",
       "      <td>37838</td>\n",
       "      <td>43004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>43038</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>201</td>\n",
       "      <td>790</td>\n",
       "      <td>4296</td>\n",
       "      <td>3193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>0003020d3c</td>\n",
       "      <td>e344ab2e71</td>\n",
       "      <td>52f13dac0c</td>\n",
       "      <td>ca69ed9de2</td>\n",
       "      <td>420c3b3f0b</td>\n",
       "      <td>0d6f137fb6</td>\n",
       "      <td>43acd80c1a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>22183</td>\n",
       "      <td>8891</td>\n",
       "      <td>3737</td>\n",
       "      <td>2500</td>\n",
       "      <td>4344</td>\n",
       "      <td>1514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        product_id     level_1     level_2     level_3     level_4  \\\n",
       "count        43038       43035       43035       43035       43035   \n",
       "unique       43038           3          42         201         790   \n",
       "top     0003020d3c  e344ab2e71  52f13dac0c  ca69ed9de2  420c3b3f0b   \n",
       "freq             1       22183        8891        3737        2500   \n",
       "\n",
       "          brand_id   vendor_id  \n",
       "count        37838       43004  \n",
       "unique        4296        3193  \n",
       "top     0d6f137fb6  43acd80c1a  \n",
       "freq          4344        1514  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Кол-во строк и столбцов:\n",
      "(43038, 11)\n",
      "****************************************************************************************************\n",
      "Кол-во пропусков:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "product_id          0.000000\n",
       "level_1             0.000070\n",
       "level_2             0.000070\n",
       "level_3             0.000070\n",
       "level_4             0.000070\n",
       "segment_id          0.036526\n",
       "brand_id            0.120823\n",
       "vendor_id           0.000790\n",
       "netto               0.000070\n",
       "is_own_trademark    0.000000\n",
       "is_alcohol          0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Кол-во дубликатов:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "get_info(df_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Описание переменных</h2>\n",
    "\n",
    "**product_id** - уникальный идентификатор продукта<br>\n",
    "**level_1-4** - подкатегории товара<br>\n",
    "**segment_id** - уникальный идентификатор сегмента рынка<br>\n",
    "**brand_id** - уникальный идентификатор бренда товара<br>\n",
    "**vendor_id** - уникальный идентификатор продавца/поставщика товара<br>\n",
    "**netto** - масса нетто товара<br>\n",
    "**is_own_trademark** -продукция собственного производства<br>\n",
    "**is_alcohol** - алкогольная продукция"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Мысли**:\n",
    "\n",
    "* Разнообразие товаров собственного производства и алкогольной продукции гораздо меньше остальных видов продукции (первых 3.5% от общего количества, вторых 5.5%)\n",
    "* Всего 3 уникальных подкатегории товара `level_1`\n",
    "* Интересно, что в `level_1` - `level_4` одинаковое число пропусков (по 3). Нужно посмотреть, относятся ли эти пропуски к одним и тем же товарам (спойлер: да)\n",
    "* Можно посмотреть количество уникальных категорий в `segment_id`, `is_own_trademark`, `is_alcohol`\n",
    "* Какие признаки брать, а какие - нет, решу позже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:21:15.009434Z",
     "iopub.status.busy": "2023-02-11T13:21:15.009038Z",
     "iopub.status.idle": "2023-02-11T13:21:15.034837Z",
     "shell.execute_reply": "2023-02-11T13:21:15.032992Z",
     "shell.execute_reply.started": "2023-02-11T13:21:15.009396Z"
    }
   },
   "outputs": [],
   "source": [
    "#проверка того, что пропуски в level_1 в тех же товарах, у которых пропуски в \n",
    "#level_2 - level_4\n",
    "df_products[df_products['level_1'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:21:15.038179Z",
     "iopub.status.busy": "2023-02-11T13:21:15.037627Z",
     "iopub.status.idle": "2023-02-11T13:21:15.053485Z",
     "shell.execute_reply": "2023-02-11T13:21:15.051738Z",
     "shell.execute_reply.started": "2023-02-11T13:21:15.038126Z"
    }
   },
   "outputs": [],
   "source": [
    "#просмотр уникальных категорий, которых не было в describe\n",
    "    \n",
    "#segment_id, is_own_trademark, is_alcohol\n",
    "for col in ['segment_id', 'is_own_trademark', 'is_alcohol']:\n",
    "    print(f'Уникальных категорий {col} : {df_products[col].nunique()}')\n",
    "    \n",
    "# is_own_trademark, is_alcohol - тут всего 2 уникальных значения, посмотрим какие\n",
    "for col in ['is_own_trademark', 'is_alcohol']:\n",
    "    print(f'Уникальные категории {col} : {df_products[col].unique()}')\n",
    "    \n",
    "#логично, что это значения 0 и 1 (но проверить стоило)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> train_purch.csv и test_purch.csv</h2>\n",
    "<a id='section_id1.4'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T15:31:30.884816Z",
     "iopub.status.busy": "2023-03-29T15:31:30.883365Z",
     "iopub.status.idle": "2023-03-29T15:32:54.071362Z",
     "shell.execute_reply": "2023-03-29T15:32:54.070111Z",
     "shell.execute_reply.started": "2023-03-29T15:31:30.884723Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train_purch = pd.read_csv(os.path.join(dirpath,train_purch_path),\n",
    "                             parse_dates = ['transaction_datetime'])\n",
    "df_test_purch = pd.read_csv(os.path.join(dirpath,test_purch_path),\n",
    "                            parse_dates = ['transaction_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:22:43.542225Z",
     "iopub.status.busy": "2023-02-11T13:22:43.541712Z",
     "iopub.status.idle": "2023-02-11T13:24:15.003869Z",
     "shell.execute_reply": "2023-02-11T13:24:15.001108Z",
     "shell.execute_reply.started": "2023-02-11T13:22:43.542185Z"
    }
   },
   "outputs": [],
   "source": [
    "#соединим таблицы в одну\n",
    "df_purch = pd.concat([df_train_purch, df_test_purch])\n",
    "get_info(df_purch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:24:15.008945Z",
     "iopub.status.busy": "2023-02-11T13:24:15.008300Z",
     "iopub.status.idle": "2023-02-11T13:24:16.154249Z",
     "shell.execute_reply": "2023-02-11T13:24:16.153227Z",
     "shell.execute_reply.started": "2023-02-11T13:24:15.008894Z"
    }
   },
   "outputs": [],
   "source": [
    "del df_train_purch, df_test_purch\n",
    "print(gc.collect())\n",
    "#занимаемая память\n",
    "return_memory(df_purch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Описание переменных</h2>\n",
    "\n",
    "**client_id** - уникальный идентификатор покупателя<br>\n",
    "**transaction_id** - уникальный идентификатор транзакции<br>\n",
    "**transaction_datetime** - дата проведения транзакции<br>\n",
    "**regular_points_received** - сумма полученных бонусных баллов<br>\n",
    "**express_points_received** - сумма полученных экстра-бонусных баллов<br>\n",
    "**regular_points_spent** - сумма потраченных бонусных баллов<br>\n",
    "**express_points_spent** - сумма потраченных экстра - бонусных баллов<br>\n",
    "**purchase_sum** - сумма покупки<br>\n",
    "**store_id** - уникальный идентификатор магазина<br>\n",
    "**product_id** - уникальный идентификатор продукта<br>\n",
    "**product_quantity** - кол-во (единиц) продукта<br>\n",
    "**trn_sum_from_iss** - стоимость товара с учетом скидки<br>\n",
    "**trn_sum_from_red** - пересчитанная стоимость товара на полке после применения скидки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Мысли**:\n",
    "\n",
    "* Видно, что ооочень много пропусков в столбце trn_sum_from_red, пропуски нужно заменить, например, на 0.\n",
    "* Остальные ячейки таблицы все заполнены, дубликатов нет\n",
    "* Можно проверить, имеются ли покупки, которые совершались клиентами не из списка train/test (спойлер: таких нет)\n",
    "* Очень большой объем памяти занимает таблица, можно поиграться с типами данных. Например float64 -> float16 или float32\n",
    "* Можно добавить временные признаки, связанные с `transaction_datetime`: в который час, день недели, месяц было событие, а также добавить дату (количество дней с 1 января 1970г)\n",
    "* Во многих столбцах записи об одной транзакции повторяются. Отличия заключаются только в купленном продукте. Поэтому не нужно суммировать каждую строчку (например, при подсчете суммы затрат), нужно брать только последнюю для каждой транзакции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:24:16.155687Z",
     "iopub.status.busy": "2023-02-11T13:24:16.155303Z",
     "iopub.status.idle": "2023-02-11T13:25:25.751909Z",
     "shell.execute_reply": "2023-02-11T13:25:25.750612Z",
     "shell.execute_reply.started": "2023-02-11T13:24:16.155653Z"
    }
   },
   "outputs": [],
   "source": [
    "#берем только те покупки, которые были совершены клиентами из train+test выборки\n",
    "df_purch = df_purch[df_purch['client_id'].isin(clients)]\n",
    "get_info(df_purch)\n",
    "#как оказалось, других клиентов и не было (но проверить стоило)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:25:25.754725Z",
     "iopub.status.busy": "2023-02-11T13:25:25.753654Z",
     "iopub.status.idle": "2023-02-11T13:25:28.772359Z",
     "shell.execute_reply": "2023-02-11T13:25:28.771109Z",
     "shell.execute_reply.started": "2023-02-11T13:25:25.754671Z"
    }
   },
   "outputs": [],
   "source": [
    "#в trn_sum_from_red пропуски заменим на 0\n",
    "df_purch['trn_sum_from_red'] = df_purch['trn_sum_from_red'].fillna(0)\n",
    "#ниже поменяем тип данных, тем самым уменьшим объем задействованной памяти\n",
    "df_purch['regular_points_received'] = df_purch['regular_points_received'].astype('float32')\n",
    "df_purch['express_points_received'] = df_purch['express_points_received'].astype('float16')\n",
    "df_purch['regular_points_spent'] = df_purch['regular_points_spent'].astype('float32')\n",
    "df_purch['express_points_spent'] = df_purch['express_points_spent'].astype('float16')\n",
    "df_purch['product_quantity'] = df_purch['product_quantity'].astype('int32')\n",
    "df_purch['purchase_sum'] = df_purch['purchase_sum'].astype('float32')\n",
    "df_purch['trn_sum_from_iss'] = df_purch['trn_sum_from_iss'].astype('float32')\n",
    "df_purch['trn_sum_from_red'] = df_purch['trn_sum_from_red'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:25:28.781152Z",
     "iopub.status.busy": "2023-02-11T13:25:28.780726Z",
     "iopub.status.idle": "2023-02-11T13:25:28.944165Z",
     "shell.execute_reply": "2023-02-11T13:25:28.942600Z",
     "shell.execute_reply.started": "2023-02-11T13:25:28.781115Z"
    }
   },
   "outputs": [],
   "source": [
    "#занимаемая память\n",
    "return_memory(df_purch) #почти в 2 раза уменьшил\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:25:28.946360Z",
     "iopub.status.busy": "2023-02-11T13:25:28.945876Z",
     "iopub.status.idle": "2023-02-11T13:25:38.223898Z",
     "shell.execute_reply": "2023-02-11T13:25:38.222461Z",
     "shell.execute_reply.started": "2023-02-11T13:25:28.946313Z"
    }
   },
   "outputs": [],
   "source": [
    "#доп-ые фичи времени по transaction_datetime\n",
    "\n",
    "#день недели от 0 до 6\n",
    "df_purch['transaction_datetime_weekday'] = df_purch['transaction_datetime'].dt.weekday.astype('object')\n",
    "#номер месяца от 1 до 12\n",
    "df_purch['transaction_datetime_month'] = df_purch['transaction_datetime'].dt.month.astype('object')\n",
    "#который час от 0 до 23\n",
    "df_purch['transaction_datetime_hour'] = df_purch['transaction_datetime'].dt.hour\n",
    "#количество дней с 1 января 1970 года\n",
    "df_purch['transaction_datetime_time'] = (df_purch['transaction_datetime'] - pd.Timestamp('1970-01-01'))//pd.Timedelta('1d')\n",
    "\n",
    "#df_purch.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Построим различные графики**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдем самые популярные/редкие магазины и товары"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:25:38.226834Z",
     "iopub.status.busy": "2023-02-11T13:25:38.226171Z",
     "iopub.status.idle": "2023-02-11T13:26:23.611655Z",
     "shell.execute_reply": "2023-02-11T13:26:23.610373Z",
     "shell.execute_reply.started": "2023-02-11T13:25:38.226771Z"
    }
   },
   "outputs": [],
   "source": [
    "#вспомогательная таблица, где данные сгруппированы по id клиента и id транзакции\n",
    "df_purch_group=df_purch.groupby(['client_id', 'transaction_id']).last()\n",
    "\n",
    "#столбец количества посещений, индекс - store_id\n",
    "df_store=df_purch_group.groupby('store_id')['transaction_datetime'].count()\n",
    "\n",
    "# 20 самых популярных магазинов: 1ый столбец store_id, 2ой - число посещений\n",
    "popular_stores=df_store.sort_values(ascending=False).reset_index().\\\n",
    "               rename(columns={'transaction_datetime': 'amount'}).head(20)\n",
    "\n",
    "# 20 самых непопулярных магазинов: 1ый столбец store_id, 2ой - число посещений\n",
    "unpopular_stores=df_store.sort_values(ascending=True).reset_index().\\\n",
    "               rename(columns={'transaction_datetime': 'amount'}).head(20)\n",
    "\n",
    "#столбец количества посещений, индекс - store_id\n",
    "df_tovar=df_purch.groupby('product_id')['store_id'].count()\n",
    "\n",
    "# 20 самых популярных товаров: 1ый столбец product_id, 2ой - число покупок товара\n",
    "popular_tovars=df_tovar.sort_values(ascending=False).reset_index().\\\n",
    "               rename(columns={'store_id': 'amount'}).head(20)\n",
    "\n",
    "# # 20 самых непопулярных товаров: 1ый столбец product_id, 2ой - число покупок товара\n",
    "# unpopular_tovars=df_tovar.sort_values(ascending=True).reset_index().\\\n",
    "#                rename(columns={'store_id': 'amount'}).head(20)\n",
    "\n",
    "'''\n",
    "как оказалось, всего 2571 товар, который покупали всего 1 раз, поэтому бессмысленно\n",
    "строить график с самыми редкими товарами\n",
    "'''\n",
    "\n",
    "#графики\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10,20))\n",
    "\n",
    "#популярные магазины\n",
    "sns.barplot(ax=axes[0], x='store_id', y='amount', data=popular_stores) \n",
    "axes[0].set(xlabel='store_id', ylabel='Количество посещений магазина',\n",
    "      title='Самые популярные магазины')  \n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(),rotation=90)\n",
    "\n",
    "#непопулярные магазины\n",
    "sns.barplot(ax=axes[1], x='store_id', y='amount', data=unpopular_stores) \n",
    "axes[1].set(xlabel='store_id', ylabel='Количество посещений магазина',\n",
    "      title='Самые редкие по посещаемости магазины')  \n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(),rotation=90)\n",
    "\n",
    "#популярные товары\n",
    "sns.barplot(ax=axes[2], x='product_id', y='amount', data=popular_tovars) \n",
    "axes[2].set(xlabel='product_id', ylabel='Количество покупок товара',\n",
    "      title='Самые популярные товары')  \n",
    "axes[2].set_xticklabels(axes[2].get_xticklabels(),rotation=90)\n",
    "\n",
    "# #непопулярные товары\n",
    "# sns.barplot(ax=axes[3], x='product_id', y='amount', data=unpopular_tovars) \n",
    "# axes[3].set(xlabel='product_id', ylabel='Количество покупок товара',\n",
    "#       title='Самые редкие товары')  \n",
    "# axes[3].set_xticklabels(axes[3].get_xticklabels(),rotation=90)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:26:23.613874Z",
     "iopub.status.busy": "2023-02-11T13:26:23.613478Z",
     "iopub.status.idle": "2023-02-11T13:26:24.390945Z",
     "shell.execute_reply": "2023-02-11T13:26:24.389452Z",
     "shell.execute_reply.started": "2023-02-11T13:26:23.613836Z"
    }
   },
   "outputs": [],
   "source": [
    "#посмотрим на распределение по сумме чека\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 5))\n",
    "\n",
    "sns.boxplot(x='purchase_sum', data=df_purch_group)\n",
    "ax.set(xlabel='Сумма чека', ylabel='Количество',\n",
    "      title='Распределение суммы чека')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В подавляющем большинстве случаев, сумма чека при покупке не превосходит 1000, но\n",
    "есть немало покупок, чек которых больше 1000, даже есть покупки на почти 30000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:26:24.393247Z",
     "iopub.status.busy": "2023-02-11T13:26:24.392828Z",
     "iopub.status.idle": "2023-02-11T13:27:18.944262Z",
     "shell.execute_reply": "2023-02-11T13:27:18.942903Z",
     "shell.execute_reply.started": "2023-02-11T13:26:24.393210Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(10,15))\n",
    "\n",
    "#по месяцам\n",
    "sns.histplot(ax=axes[0], x='transaction_datetime_month', data=df_purch_group, \n",
    "             discrete=True) \n",
    "axes[0].set(xlabel='Месяц', ylabel='Количество', xticks=np.arange(1, 13, 1),\n",
    "      title='Распределение количества покупок по месяцам')  \n",
    "\n",
    "#по дням недели\n",
    "sns.histplot(ax=axes[1], x='transaction_datetime_weekday', data=df_purch_group, \n",
    "             discrete=True) \n",
    "axes[1].set(xlabel='День недели', ylabel='Количество', xticks=np.arange(0, 7, 1), \n",
    "            xticklabels=['пн','вт','ср', 'чт', 'пт','сб', 'вс'],\n",
    "            title='Распределение количества покупок по дням недели')  \n",
    "\n",
    "#по часам\n",
    "sns.histplot(ax=axes[2], x='transaction_datetime_hour', data=df_purch_group, \n",
    "             discrete=True) \n",
    "axes[2].set(xlabel='Время в часах', ylabel='Количество', xticks=np.arange(0, 24, 1), \n",
    "      title='Распределение количества покупок по времени суток')  \n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#df_purch.transaction_datetime_month.unique() - покупки были только с ноября по март"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Анализируя графики, можно прийти к выводу о том, что покупки происходили с ноября по март. В ноябре и в марте было совершено меньше покупок (это связано с тем, что покупки начали совершаться с середины ноября и закончились в середине марта). Распределение количества покупок по дням выглядит примерно равномерным несмотря на то, что казалось бы, что в выходные должно быть больше заказов. Распределение по времени суток явно не является равномерным - ночью заказов меньше, а пики наблюдаются в 9 утра и в 2 часа дня (14 часов)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Feature Engineering**\n",
    "<a id='section_id2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смержим инфу про продукты, покупки и клиентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:27:18.946723Z",
     "iopub.status.busy": "2023-02-11T13:27:18.946174Z",
     "iopub.status.idle": "2023-02-11T13:28:10.803292Z",
     "shell.execute_reply": "2023-02-11T13:28:10.801887Z",
     "shell.execute_reply.started": "2023-02-11T13:27:18.946668Z"
    }
   },
   "outputs": [],
   "source": [
    "#merge products, purch, clients\n",
    "df_all = pd.merge(df_purch, df_products, how='left', on='product_id')\n",
    "df_all = pd.merge(df_all, df_clients, how='left', on='client_id')\n",
    "print(df_all.shape)\n",
    "\n",
    "#df_all.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:28:10.805685Z",
     "iopub.status.busy": "2023-02-11T13:28:10.805201Z",
     "iopub.status.idle": "2023-02-11T13:28:10.987464Z",
     "shell.execute_reply": "2023-02-11T13:28:10.986001Z",
     "shell.execute_reply.started": "2023-02-11T13:28:10.805636Z"
    }
   },
   "outputs": [],
   "source": [
    "#занимаемая память\n",
    "return_memory(df_all)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:28:10.989823Z",
     "iopub.status.busy": "2023-02-11T13:28:10.989276Z",
     "iopub.status.idle": "2023-02-11T13:28:11.006871Z",
     "shell.execute_reply": "2023-02-11T13:28:11.005398Z",
     "shell.execute_reply.started": "2023-02-11T13:28:10.989771Z"
    }
   },
   "outputs": [],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Мысли**:\n",
    "\n",
    "* Сумма затрат перед использованием карты лояльности/после\n",
    "* Для каждого клиента на каждый день недели: количество транзакций, сумма `trn_sum_form_iss`\n",
    "* Для каждого часа: количество транзакций\n",
    "* Для каждого клиента расчет`trn_sum_from_iss` суммы при покупке алкоголя/ при покупке собственной продукции. \n",
    "* Для каждого клиента подсчет количества покупок, `trn_sum_from_iss` сумма которых превосходит определенного значения.\n",
    "* Для каждого клиента разность между последним и первым днем покупки.\n",
    "\n",
    "    **Покупки за все время**:\n",
    "\n",
    "* Сумма всех баллов и затрат\n",
    "* Количество, среднее и стандартное отклонение транзакций\n",
    "* Среднее и стандартное отклонение всех баллов\n",
    "* Количество уникальных магазинов\n",
    "\n",
    "    **Покупки за последний месяц**:\n",
    "* Сумма всех баллов и затрат\n",
    "* Количество транзакций\n",
    "* Количество уникальных магазинов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сумма затрат и количество покупок перед использованием бонусной карты/после**\n",
    "<a id='section_id2.1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:28:11.008714Z",
     "iopub.status.busy": "2023-02-11T13:28:11.008311Z",
     "iopub.status.idle": "2023-02-11T13:29:05.220305Z",
     "shell.execute_reply": "2023-02-11T13:29:05.218857Z",
     "shell.execute_reply.started": "2023-02-11T13:28:11.008680Z"
    }
   },
   "outputs": [],
   "source": [
    "def before_after_redeem_manipulations(df_clients, df):\n",
    "\n",
    "    # Разница дат\n",
    "    df['ord_diff'] = df['first_redeem_time'] - df['transaction_datetime_time']\n",
    "\n",
    "    # Датафреймы с положительной/отрицательной разницей\n",
    "    df_before = df[df['ord_diff'] > 0][['client_id', 'transaction_id', 'purchase_sum']]\n",
    "    df_after = df[df['ord_diff'] <= 0][['client_id', 'transaction_id', 'purchase_sum']]\n",
    "\n",
    "    # Берем последнюю запись (уже говорилось ранее почему при просмотре таблицы df_purch)\n",
    "    df_before_all = df_before.groupby(['client_id', 'transaction_id']).last()\n",
    "    df_after_all = df_after.groupby(['client_id', 'transaction_id']).last()\n",
    "\n",
    "    # Считаем суммы\n",
    "    ds_before_sum = df_before_all.groupby('client_id')['purchase_sum'].sum()\n",
    "    ds_after_sum = df_after_all.groupby('client_id')['purchase_sum'].sum()\n",
    "\n",
    "    # Считаем количество операций\n",
    "    ds_before_counters = df_before_all.groupby('client_id')['purchase_sum'].count()    \n",
    "    ds_after_counters = df_after_all.groupby('client_id')['purchase_sum'].count()    \n",
    "\n",
    "    ds_before_sum.name = 'before_redeem_sum'\n",
    "    ds_after_sum.name = 'after_redeem_sum'\n",
    "\n",
    "    ds_before_counters.name = 'before_redeem_counter'\n",
    "    ds_after_counters.name = 'after_redeem_counter'\n",
    "\n",
    "    # Мержим\n",
    "    df_clients = pd.merge(df_clients, ds_before_sum, how='left', on='client_id')    \n",
    "    df_clients = pd.merge(df_clients, ds_after_sum, how='left', on='client_id')    \n",
    "\n",
    "    df_clients = pd.merge(df_clients, ds_before_counters, how='left', on='client_id')    \n",
    "    df_clients = pd.merge(df_clients, ds_after_counters, how='left', on='client_id')     \n",
    "    \n",
    "    return df_clients\n",
    "\n",
    "#тут же вызываем\n",
    "df_clients = before_after_redeem_manipulations(df_clients, df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Для каждого клиента на каждый день недели: количество транзакций, сумма `trn_sum_from_iss`**\n",
    "<a id='section_id2.2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:29:05.222739Z",
     "iopub.status.busy": "2023-02-11T13:29:05.222156Z",
     "iopub.status.idle": "2023-02-11T13:29:51.607825Z",
     "shell.execute_reply": "2023-02-11T13:29:51.606372Z",
     "shell.execute_reply.started": "2023-02-11T13:29:05.222689Z"
    }
   },
   "outputs": [],
   "source": [
    "def day_of_week_manipulations(df_clients, df):\n",
    "\n",
    "    for i in range(7):\n",
    "        # Группируем по каждому дню недели\n",
    "        df_dayfiltered = df[df['transaction_datetime_weekday'] == i][['client_id', 'transaction_id', \n",
    "                                                                   'transaction_datetime_weekday', 'trn_sum_from_iss']]\n",
    "        ds_purch_day_of_week = df_dayfiltered.groupby(['client_id', 'transaction_id']).last()\n",
    "        # Считаем количество транзакций по каждому дню недели\n",
    "        ds_counters = ds_purch_day_of_week.groupby('client_id')['transaction_datetime_weekday'].count()\n",
    "        ds_counters.name = f'amount_purch_in_dow_{i}'\n",
    "        df_clients = pd.merge(df_clients, ds_counters, how='left', on='client_id')\n",
    "\n",
    "        # Считаем сумму trn_sum_from_iss по каждому дню недели\n",
    "        ds_purch_day_of_week = df_dayfiltered.groupby('client_id')['trn_sum_from_iss'].sum()\n",
    "        ds_purch_day_of_week.name = f'total_sum_purch_in_dow_{i}'\n",
    "        df_clients = pd.merge(df_clients, ds_purch_day_of_week, how='left', on='client_id')\n",
    "        \n",
    "    return df_clients\n",
    "\n",
    "#тут же вызываем\n",
    "df_clients = day_of_week_manipulations(df_clients, df_purch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-31T20:19:58.430289Z",
     "iopub.status.busy": "2023-01-31T20:19:58.429704Z",
     "iopub.status.idle": "2023-01-31T20:19:58.439878Z",
     "shell.execute_reply": "2023-01-31T20:19:58.437890Z",
     "shell.execute_reply.started": "2023-01-31T20:19:58.430238Z"
    }
   },
   "source": [
    "**Для каждого клиента на каждый час дня: количество транзакций (без суммы `trn_sum_from_iss`)**\n",
    "<a id='section_id2.3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Схема такая же, как и в day_of_week_manipulations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:29:51.610852Z",
     "iopub.status.busy": "2023-02-11T13:29:51.609698Z",
     "iopub.status.idle": "2023-02-11T13:30:24.881162Z",
     "shell.execute_reply": "2023-02-11T13:30:24.879818Z",
     "shell.execute_reply.started": "2023-02-11T13:29:51.610807Z"
    }
   },
   "outputs": [],
   "source": [
    "def hours_manipulations(df_clients, df):\n",
    "\n",
    "    for i in range(24):\n",
    "        df_hourfiltered = df[df['transaction_datetime_hour'] == i][['client_id', 'transaction_id', 'transaction_datetime_hour']]\n",
    "        ds_purch_hour = df_hourfiltered.groupby(['client_id', 'transaction_id']).last()\n",
    "        ds_counters = ds_purch_hour.groupby('client_id')['transaction_datetime_hour'].count()\n",
    "        ds_counters.name = f'amount_purch_in_hour_{i}'\n",
    "        df_clients = pd.merge(df_clients, ds_counters, how='left', on='client_id')\n",
    "\n",
    "    return df_clients\n",
    "\n",
    "#тут же вызываем\n",
    "df_clients = hours_manipulations(df_clients, df_purch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**а) Для каждого клиента расчет`trn_sum_from_iss` суммы при покупке алкоголя/ при покупке собственной продукции. <br> \n",
    "б) Для каждого клиента подсчет количества покупок, `trn_sum_from_iss` сумма которых превосходит определенного значения. <br>\n",
    "в) Для каждого клиента разность между последним и первым днем покупки.**\n",
    "<a id='section_id2.4'></a> <a id='section_id2.5'></a> <a id='section_id2.6'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:30:24.883000Z",
     "iopub.status.busy": "2023-02-11T13:30:24.882627Z",
     "iopub.status.idle": "2023-02-11T13:31:58.294630Z",
     "shell.execute_reply": "2023-02-11T13:31:58.291342Z",
     "shell.execute_reply.started": "2023-02-11T13:30:24.882965Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_all['trn_sum_from_iss'].describe()\n",
    "\n",
    "#Сначала взял значения 1ого, 2ого, 3его квартиля, ну а вдобавок от себя пару значений, но потом \n",
    "#после подсчета парных коэффициентов корреляции понял, что нельзя так делать - будем сильная \n",
    "# корреляция со средним чеком покупки, поэтому было выбраны все значения от себя, но из \n",
    "#предположения о том, что это будет больше, чем значение 3его квартиля\n",
    "\n",
    "sum_filter = [250, 500, 750, 1000, 2000] \n",
    "\n",
    "def trn_sum_manipulations(df_clients, df):\n",
    "    \n",
    "    # Считаем сумму 'trn_sum_from_iss' для покупок алкоголя\n",
    "    df_filtered = df[df['is_alcohol'] == 1][['client_id', 'trn_sum_from_iss']]\n",
    "    ds_alco = df_filtered.groupby('client_id')['trn_sum_from_iss'].sum()\n",
    "    ds_alco.name = 'sum_alco'\n",
    "    df_clients = pd.merge(df_clients, ds_alco, how='left', on='client_id')    \n",
    "\n",
    "    # Считаем сумму 'trn_sum_from_iss' для покупок собственной продукции\n",
    "    df_filtered = df[df['is_own_trademark'] == 1][['client_id', 'trn_sum_from_iss']]\n",
    "    ds_marked = df_filtered.groupby('client_id')['trn_sum_from_iss'].sum()\n",
    "    ds_marked.name = 'sum_own_trademark'\n",
    "    df_clients = pd.merge(df_clients, ds_marked, how='left', on='client_id')    \n",
    "    \n",
    "    # Rоличество покупок, сумма которых больше,чем пороговые значения в sum_filter\n",
    "    for threshold in sum_filter:\n",
    "        df_filtered = df[df['trn_sum_from_iss'] > threshold][['client_id', 'trn_sum_from_iss']]\n",
    "        ds_threshold = df_filtered.groupby('client_id')['trn_sum_from_iss'].count()\n",
    "        ds_threshold.name = f'amount_purch_where_sum_over_{threshold}'\n",
    "        df_clients = pd.merge(df_clients, ds_threshold, how='left', on='client_id')    \n",
    "\n",
    "    # Разность между последним/первым днем покупки\n",
    "    df['delta_days'] = df.groupby('client_id')['transaction_datetime_time'].transform(lambda x: x.max()-x.min()+1)\n",
    "    df_delta = df.groupby('client_id').last()['delta_days']\n",
    "    df_clients = pd.merge(df_clients, df_delta, how='left', on='client_id')\n",
    "    \n",
    "    return df_clients\n",
    "\n",
    "#тут же вызываем\n",
    "df_clients = trn_sum_manipulations(df_clients, df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создано уже много признаков, в которых много пустых значений => заполним нулями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:31:58.300781Z",
     "iopub.status.busy": "2023-02-11T13:31:58.300304Z",
     "iopub.status.idle": "2023-02-11T13:32:00.714449Z",
     "shell.execute_reply": "2023-02-11T13:32:00.712979Z",
     "shell.execute_reply.started": "2023-02-11T13:31:58.300742Z"
    }
   },
   "outputs": [],
   "source": [
    "df_clients = df_clients.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Покупки за все время и за последний месяц</h2>\n",
    "<a id='section_id2.7'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:32:00.716703Z",
     "iopub.status.busy": "2023-02-11T13:32:00.716182Z",
     "iopub.status.idle": "2023-02-11T13:32:35.906176Z",
     "shell.execute_reply": "2023-02-11T13:32:35.904846Z",
     "shell.execute_reply.started": "2023-02-11T13:32:00.716653Z"
    }
   },
   "outputs": [],
   "source": [
    "last_cols = ['regular_points_received', 'express_points_received', 'regular_points_spent',\n",
    "             'express_points_spent', 'purchase_sum', 'store_id']\n",
    "grouped_cols = df_purch.groupby(['client_id', 'transaction_id'])[last_cols].last()\n",
    "last_month = df_purch[df_purch['transaction_datetime'] >\n",
    "                          '2019-02-18'].groupby(['client_id', 'transaction_id'])[last_cols].last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:32:35.908024Z",
     "iopub.status.busy": "2023-02-11T13:32:35.907666Z",
     "iopub.status.idle": "2023-02-11T13:32:40.646273Z",
     "shell.execute_reply": "2023-02-11T13:32:40.644889Z",
     "shell.execute_reply.started": "2023-02-11T13:32:35.907989Z"
    }
   },
   "outputs": [],
   "source": [
    "features =  pd.concat([grouped_cols.groupby('client_id')['purchase_sum'].count(),\n",
    "                       last_month.groupby('client_id')['purchase_sum'].count(),\n",
    "                       grouped_cols.groupby('client_id')['purchase_sum'].mean(),\n",
    "                       grouped_cols.groupby('client_id')['purchase_sum'].std(),\n",
    "                       grouped_cols.groupby('client_id')['express_points_spent'].mean(),\n",
    "                       grouped_cols.groupby('client_id')['express_points_spent'].std(),\n",
    "                       grouped_cols.groupby('client_id')['express_points_received'].mean(),\n",
    "                       grouped_cols.groupby('client_id')['express_points_received'].std(),\n",
    "                       grouped_cols.groupby('client_id')['regular_points_spent'].mean(),\n",
    "                       grouped_cols.groupby('client_id')['regular_points_spent'].std(),\n",
    "                       grouped_cols.groupby('client_id')['regular_points_received'].mean(),\n",
    "                       grouped_cols.groupby('client_id')['regular_points_received'].std(),\n",
    "                       grouped_cols.groupby('client_id').sum(),\n",
    "                       grouped_cols.groupby('client_id')[['store_id']].nunique(),\n",
    "                       last_month.groupby('client_id').sum(),\n",
    "                       last_month.groupby('client_id')[['store_id']].nunique(),\n",
    "                      ],axis = 1)\n",
    "\n",
    "features.columns = ['total_transactions_count', 'last_month_transactions_count',\n",
    "                    'mean_purchase', 'std_purchase', 'mean_e_points_spent', 'std_e_points_spent',\n",
    "                    'mean_e_points_recd', 'std_e_points_recd', 'mean_r_points_spent', 'std_r_points_spent',\n",
    "                    'mean_r_points_recd', 'std_r_points_recd'] + \\\n",
    "                    list(c+\"_sum_all\" for c in last_cols) + list(c+\"_sum_last_month\" for c in last_cols)\n",
    "\n",
    "features  = features.reset_index() #до этого момента client_id был индексом\n",
    "features = features.fillna(0) # в дисперсиях есть пропуски"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T08:59:54.702980Z",
     "iopub.status.busy": "2023-02-01T08:59:54.702638Z",
     "iopub.status.idle": "2023-02-01T08:59:54.710857Z",
     "shell.execute_reply": "2023-02-01T08:59:54.708721Z",
     "shell.execute_reply.started": "2023-02-01T08:59:54.702956Z"
    }
   },
   "source": [
    "Объединяем фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:32:40.648460Z",
     "iopub.status.busy": "2023-02-11T13:32:40.648035Z",
     "iopub.status.idle": "2023-02-11T13:32:41.364892Z",
     "shell.execute_reply": "2023-02-11T13:32:41.363551Z",
     "shell.execute_reply.started": "2023-02-11T13:32:40.648422Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df_clients.merge(features, how='inner', on='client_id')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Новые мысли по фичам**:\n",
    "\n",
    "* Нужно убрать столбцы `first_issue_date` и `first_redeem_date`, т.к. уже есть столбцы `first_issue_time` и `first_redeem_time`, отражающие даты событий. \n",
    "* Для каждого клиента вычислить долю затрат на алкоголь от общих затрат, то же самое проделать с товарами собственного производства\n",
    "* Разность между последним днем 19 марта 2019 года и `first_issue_time`,  `first_redeem_time` (хотя возможно появится сильная корреляция с другими временными признаками, потом нужно проверить)\n",
    "* Для каждого клиента вычислить отношение количества покупок, сумма которых выше порогового значения к количеству покупок в целом\n",
    "* Для каждого клиента вычислить долю покупок по количеству/ по сумме в каждый день недели\n",
    "* Для каждого клиента вычислить долю покупок по количеству в каждый час дня\n",
    "* Для каждого клиента вычислить долю покупок по количеству/ по сумме до и после использования бонусной карты\n",
    "* Средняя сумма чека в день\n",
    "* Средняя сумма потраченная на алкоголь/продукты собственного производства в день\n",
    "* Средняя сумма покупки после первого использования бонусной карты в день\n",
    "* Средняя сумма потраченных/полученных разных бонусных баллов в день\n",
    "* Разность полученных баллов и потраченных за последний месяц\n",
    "\n",
    "<a id='section_id2.8'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:32:41.367123Z",
     "iopub.status.busy": "2023-02-11T13:32:41.366744Z",
     "iopub.status.idle": "2023-02-11T13:32:41.601586Z",
     "shell.execute_reply": "2023-02-11T13:32:41.600193Z",
     "shell.execute_reply.started": "2023-02-11T13:32:41.367088Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_new_features(df):\n",
    "\n",
    "    '''\n",
    "    удаление столбцов first_issue_date и first_redeem_date (т.к. уже есть столбцы\n",
    "    first_issue_time и first_redeem_time)\n",
    "    '''\n",
    "    df.drop(columns=['first_issue_date', 'first_redeem_date'],inplace=True)\n",
    "    \n",
    "    # доля затрат на алкоголь/собственную продукцию\n",
    "    df['alco_ratio'] = df['sum_alco'] / df['purchase_sum_sum_all']\n",
    "    df['own_trademark_ratio'] = df['sum_own_trademark'] / df['purchase_sum_sum_all']\n",
    "    \n",
    "    # разность между последним днем и датами\n",
    "    cutoff_dt = date.toordinal(date(2019, 3, 19)) #тут номер дня с 1 января 1 года\n",
    "    df['issue_diff'] = cutoff_dt - df['first_issue_time']\n",
    "    df['redeem_diff'] = cutoff_dt - df['first_redeem_time']\n",
    "\n",
    "    # отношение количества покупок выше порогового значения к количеству покупок в целом\n",
    "    for threshold in sum_filter:\n",
    "        df[f'sum_over_{threshold}_ratio'] = df[f'amount_purch_where_sum_over_{threshold}'] / df['total_transactions_count']\n",
    "\n",
    "    # доля покупок в определенный день недели\n",
    "    for i in range(7):\n",
    "        df[f'amount_purch_ratio_in_dow_{i}'] = df[f'amount_purch_in_dow_{i}'] / df['total_transactions_count']\n",
    "        df[f'total_sum_purch_ratio_in_dow_{i}'] = df[f'total_sum_purch_in_dow_{i}'] / df['purchase_sum_sum_all']\n",
    "\n",
    "    # доля покупок в определенный час\n",
    "    for i in range(24):\n",
    "        df[f'amount_purch_ratio_in_hour_{i}'] = df[f'amount_purch_in_hour_{i}'] / df['total_transactions_count']\n",
    "\n",
    "    # доля суммы покупок перед/после первого использования бонусной карты\n",
    "    df['before_redeem_sum_ratio'] = df['before_redeem_sum'] / df['purchase_sum_sum_all']\n",
    "    df['after_redeem_sum_ratio'] = df['after_redeem_sum'] / df['purchase_sum_sum_all']\n",
    "    \n",
    "    # доля количества покупок перед/после использования бонусной карты\n",
    "    df['before_redeem_counter_ratio'] = df['before_redeem_counter'] / df['total_transactions_count']\n",
    "    df['after_redeem_counter_ratio'] = df['after_redeem_counter'] / df['total_transactions_count']\n",
    "\n",
    "    # средняя сумма покупок в день\n",
    "    df['avg_spent_perday'] = df['purchase_sum_sum_all'] / df['delta_days']\n",
    "    #сумма покупок алкоголя/товаров собственного производства в день\n",
    "    df['sum_alco_perday'] = df['sum_alco'] / df['delta_days']\n",
    "    df['sum_own_trademark_perday'] = df['sum_own_trademark'] / df['delta_days']\n",
    "    \n",
    "    # Средняя сумма покупки после первого использования бонусной карты в день\n",
    "    df['after_redeem_sum_perday'] = df['after_redeem_sum'] / df['delta_days']\n",
    "    \n",
    "    # Средняя сумма потраченных/полученных разных бонусных баллов в день\n",
    "    df['e_points_spent_perday'] = df['express_points_spent_sum_all'] / df['delta_days']\n",
    "    df['r_points_spent_perday'] = df['regular_points_spent_sum_all'] / df['delta_days']\n",
    "    df['e_points_received_perday'] = df['express_points_received_sum_all'] / df['delta_days']\n",
    "    df['r_points_received_perday'] = df['regular_points_received_sum_all'] / df['delta_days']\n",
    "\n",
    "    # баллы, оставшиеся в последний месяц\n",
    "    df['r_points_available_last_month'] = df['regular_points_received_sum_last_month'] - df['regular_points_spent_sum_last_month']\n",
    "    df['e_points_available_last_month'] = df['express_points_received_sum_last_month'] - df['express_points_spent_sum_last_month']    \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "#тут же вызываем\n",
    "df=prepare_new_features(df)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили 145 столбцов в таблице `df` (столбец `client_id` и еще 144 фичи)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Анализ признаков**\n",
    "\n",
    "<a id='section_id3'></a>\n",
    "Проведем анализ получившихся признаков и удалим лишние из них. Лишними признаками будут являться те, которые сильно коррелируют с другими признаками, а также те, важность которых мала, если провести неглубокое обучение. Для этого воспользуемся библиотекой FeatureSelector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:32:41.603473Z",
     "iopub.status.busy": "2023-02-11T13:32:41.603050Z",
     "iopub.status.idle": "2023-02-11T13:32:47.675127Z",
     "shell.execute_reply": "2023-02-11T13:32:47.673601Z",
     "shell.execute_reply.started": "2023-02-11T13:32:41.603435Z"
    }
   },
   "outputs": [],
   "source": [
    "'''Разделение на тренировочный и тестовый датасет'''\n",
    "\n",
    "train_X = df_train.merge(df, how='inner', on='client_id')\n",
    "train_X.drop(columns=['client_id'],inplace=True)\n",
    "\n",
    "test_X = df_test.merge(df, how='inner', on='client_id')\n",
    "test_X.drop(columns=['client_id'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отличие между тренировочным и тестовым датасетом заключается в том, что в тренировочном есть 2 столбца `treatment_flg` и `purchased`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для использования функций библиотеки Feature Selector, нужно из `treatment_flg` и `purchased` сделать один`target`, который равен единице ,если `treatment_flg` равен`purchased` и 0 в противном случае."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:32:47.676766Z",
     "iopub.status.busy": "2023-02-11T13:32:47.676378Z",
     "iopub.status.idle": "2023-02-11T13:32:47.745795Z",
     "shell.execute_reply": "2023-02-11T13:32:47.744554Z",
     "shell.execute_reply.started": "2023-02-11T13:32:47.676732Z"
    }
   },
   "outputs": [],
   "source": [
    "train_X['target']=0\n",
    "train_X['target']=(train_X['purchased']+train_X['treatment_flg']+1)%2\n",
    "\n",
    "# удаляем колонки, из которых сгенерировали целевую переменную, \n",
    "#сохраняем в train_X_check, в котором будет искать плохие признаки\n",
    "train_X_check = train_X.drop(columns=['treatment_flg', 'purchased'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:32:47.748240Z",
     "iopub.status.busy": "2023-02-11T13:32:47.747683Z",
     "iopub.status.idle": "2023-02-11T13:32:47.803132Z",
     "shell.execute_reply": "2023-02-11T13:32:47.801820Z",
     "shell.execute_reply.started": "2023-02-11T13:32:47.748201Z"
    }
   },
   "outputs": [],
   "source": [
    "train=train_X_check.drop(columns = ['target']) #только признаки\n",
    "train_labels = train_X_check['target'] #таргет\n",
    "\n",
    "#создание Feature Selector\n",
    "fs = FeatureSelector(data = train, labels = train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Поиск признаков, в которых большое количество пропусков (вообще их не должно быть) и которые имеют сильную парную корреляцию**\n",
    "<a id='section_id3.1'></a> <a id='section_id3.2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:32:47.805759Z",
     "iopub.status.busy": "2023-02-11T13:32:47.805260Z",
     "iopub.status.idle": "2023-02-11T13:33:00.023804Z",
     "shell.execute_reply": "2023-02-11T13:33:00.022473Z",
     "shell.execute_reply.started": "2023-02-11T13:32:47.805717Z"
    }
   },
   "outputs": [],
   "source": [
    "MISSING_RATIO_MAX = 0.01 \n",
    "PAIR_CORRELATION_MAX = 0.7\n",
    "\n",
    "'''фичи, в которых пропусков больше, чем missing_threshold'''\n",
    "fs.identify_missing(missing_threshold = MISSING_RATIO_MAX)\n",
    "fs.missing_stats\n",
    "# список таких признаков\n",
    "missing_features = fs.ops['missing'] \n",
    "fs.plot_missing()\n",
    "\n",
    "'''фичи, парная корреляция между которых очень сильная'''\n",
    "#correlation_threshold - порог, выше которого парная корреляция считается большой\n",
    "fs.identify_collinear(correlation_threshold = PAIR_CORRELATION_MAX)\n",
    "fs.plot_collinear()\n",
    "# список таких признаков\n",
    "collinear_features = fs.ops['collinear']\n",
    "#fs.record_collinear # подробная информация о сильно коррелирующих признаках"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проведем пробное обучение модели с помощью LGBM классификатора, чтобы выяснить наименее важные фичи (фичи нулевой важности)**\n",
    "<a id='section_id3.3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:33:00.026334Z",
     "iopub.status.busy": "2023-02-11T13:33:00.025843Z",
     "iopub.status.idle": "2023-02-11T13:38:19.295882Z",
     "shell.execute_reply": "2023-02-11T13:38:19.294219Z",
     "shell.execute_reply.started": "2023-02-11T13:33:00.026286Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_FEATURES_FOR_PLOT=20\n",
    "THRESHOLD_IMPORTANCE=0.8\n",
    "\n",
    "'''фичи нулевой важности'''\n",
    "fs.identify_zero_importance(task='classification', eval_metric='auc', \n",
    "                            n_iterations=50, early_stopping=True)\n",
    "#task=classification/regression\n",
    "#eval_metric - метрика для ранней остановки (не нужна, если early_stopping=False)\n",
    "#n_iterations - количество прогонов обучения для усреднения важности\n",
    "#early_stopping - включение/отключение ранней остановки\n",
    "\n",
    "#список таких признаков\n",
    "zero_importance_features=fs.ops['zero_importance']\n",
    "\n",
    "'''\n",
    "Построение графиков: 1ый - самые важные признаки, \n",
    "2ой - распределение относительной важности признаков + определение количества\n",
    "признаков, относительная важность которых больше threshold'''\n",
    "fs.plot_feature_importances(threshold = THRESHOLD_IMPORTANCE, \n",
    "                            plot_n = NUM_FEATURES_FOR_PLOT)\n",
    "\n",
    "'''\n",
    "наименее важные признаки, которые не нужны для достижения cumulative_importance от\n",
    "общей важности признаков (решил не искать их)\n",
    "'''\n",
    "#fs.identify_low_importance(cumulative_importance = 0.99)\n",
    "#low_importance_features = fs.ops['low_importance']\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Удаление \"плохих\" признаков**\n",
    "<a id='section_id3.4'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:38:19.298651Z",
     "iopub.status.busy": "2023-02-11T13:38:19.298135Z",
     "iopub.status.idle": "2023-02-11T13:38:19.352562Z",
     "shell.execute_reply": "2023-02-11T13:38:19.350063Z",
     "shell.execute_reply.started": "2023-02-11T13:38:19.298598Z"
    }
   },
   "outputs": [],
   "source": [
    "#получение списка признаков для удаления\n",
    "features_to_delete=missing_features+collinear_features+zero_importance_features\n",
    "print(len(features_to_delete))\n",
    "\n",
    "#удаление плохих признаков (и еще столбца target)\n",
    "train_X.drop(columns = features_to_delete+['target'], inplace=True)\n",
    "test_X.drop(columns = features_to_delete, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Обучение моделей**\n",
    "<a id='section_id4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда совершалось предобучение для поиска признаков нулевой важности, то из раза в раз количество таких признаков немного меняется (+-3 признака). В feature_selector вроде бы нельзя зафиксировать random_state, поэтому я решил сохранить один из результатов итоговых датасетов `train_X`, `test_X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:38:19.356023Z",
     "iopub.status.busy": "2023-02-11T13:38:19.355332Z",
     "iopub.status.idle": "2023-02-11T13:38:23.540560Z",
     "shell.execute_reply": "2023-02-11T13:38:23.538945Z",
     "shell.execute_reply.started": "2023-02-11T13:38:19.355977Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Сохранение датасетов\n",
    "# train_X.to_csv('train_X.csv',index=False)\n",
    "# test_X.to_csv('test_X.csv',index=False)\n",
    "\n",
    "#загрузка таблиц best_results и history_of_scores\n",
    "train_X = pd.read_csv('/kaggle/input/final-datasets/train_X.csv')\n",
    "test_X = pd.read_csv('/kaggle/input/final-datasets/test_X.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Деление на X_train, y_train и treat_train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:38:23.543042Z",
     "iopub.status.busy": "2023-02-11T13:38:23.542410Z",
     "iopub.status.idle": "2023-02-11T13:38:23.583296Z",
     "shell.execute_reply": "2023-02-11T13:38:23.581896Z",
     "shell.execute_reply.started": "2023-02-11T13:38:23.542968Z"
    }
   },
   "outputs": [],
   "source": [
    "# Тренировочная выборка\n",
    "X_train = train_X.drop(columns=['treatment_flg', 'purchased'])\n",
    "y_train = train_X['purchased']\n",
    "treat_train = train_X['treatment_flg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Построение модели машинного обучения.**\n",
    "<a id='section_id4.1'></a>\n",
    "\n",
    "В целом, решение поставленной задачи сводится к определению величины `uplift` для каждого клиента из тестового набора.\n",
    "\n",
    "$$ uplift = A - B, $$\n",
    "где <br>\n",
    "\n",
    "$A$ - доля людей, совершивших покупку, от всех людей, с которые было произведено взаимодействие. <br>\n",
    "$B$ - доля людей, совершивших покупку, от всех людей, с которые не было взаимодействия. <br>\n",
    "\n",
    "То есть необходимо определить на сколько изменится вероятность покупки клиентом после воздействия на него. Существует несколько подходов к решению данной задачи:\n",
    "- `Одна модель с признаком коммуникации`: модель обучается одновременно на двух группах, при этом бинарный флаг коммуникации выступает в качестве дополнительного признака. Каждый объект из тестовой выборки скорится дважды: с флагом коммуникации равным 1 и равным 0. Вычитая вероятности по каждому наблюдению, получается искомый uplift;\n",
    "- `Одна модель с трансформацией классов`: данный подход основан на преобразовании, по сути, двух таргетов в один и обучении одной модели машинного обучения на данных с изменённой целевой переменной;\n",
    "- `Две независимые модели`: подход заключается в моделировании условных вероятностей тестовой и контрольной групп отдельно;\n",
    "- `Две зависимые модели`: идея состоит в том, что в начале обучается классификатор по контрольным данным, затем используются предсказания в качестве нового признака для обучения второго классификатора на тестовых данных\n",
    "\n",
    "Выбор подхода будем осуществлять исходя из полученных результатов при каждом из них на валидационной выборке. Для решения задачи применялись следующие модели машинного обучения:\n",
    "- LGBMClassifier\n",
    "- CatBoostClassifier\n",
    "- RandomForestClassifier\n",
    "\n",
    "Подбор гиперпараметров осуществлялся методом байесовской оптимизации с помощью hyperopt - популярной python-библиотеки для подбора гиперпарметров. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Функция получения различных метрик**\n",
    "<a id='section_id4.2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:38:23.585991Z",
     "iopub.status.busy": "2023-02-11T13:38:23.585433Z",
     "iopub.status.idle": "2023-02-11T13:38:23.599987Z",
     "shell.execute_reply": "2023-02-11T13:38:23.598685Z",
     "shell.execute_reply.started": "2023-02-11T13:38:23.585937Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_scores(model,X_train, X_val, y_train, y_val, treat_train, treat_val):\n",
    "    \"\"\" Принимается модель\n",
    "        Возвращаются 3 вида score: \n",
    "        1) uplift_at_k - uplift в первых k наблюдениях (по умолчанию k=30%)\n",
    "        2) uplift_auc_score - площадь под графиком аплифта(Area Under the Uplift Curve) \n",
    "        3) qini_auc_score - Area Under the Qini curve (aka Qini coefficient)\n",
    "    \"\"\"\n",
    "    model.fit(X_train, y_train, treat_train)\n",
    "    uplift = model.predict(X_val)\n",
    "    upl_at_k = uplift_at_k(y_true=y_val, uplift=uplift, treatment=treat_val, \n",
    "                       strategy='by_group') #strategy- 'overall' или 'by_group'.\n",
    "    upl_auc = uplift_auc_score(y_true=y_val, uplift=uplift, treatment=treat_val)\n",
    "    upl_qini = qini_auc_score(y_true=y_val, uplift=uplift, treatment=treat_val)\n",
    "    \n",
    "    return {'upl_at_k': upl_at_k, 'upl_auc': upl_auc, 'upl_qini': upl_qini}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пространства гиперпараметров, инициализация кросс-валидатора**\n",
    "<a id='section_id4.3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:38:23.603016Z",
     "iopub.status.busy": "2023-02-11T13:38:23.601734Z",
     "iopub.status.idle": "2023-02-11T13:38:23.621374Z",
     "shell.execute_reply": "2023-02-11T13:38:23.619775Z",
     "shell.execute_reply.started": "2023-02-11T13:38:23.602895Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_SPLITS=5\n",
    "\n",
    "# инициализируем кросс-валидатор\n",
    "kf = StratifiedKFold(n_splits = NUM_SPLITS, shuffle = True, random_state = 42)\n",
    "\n",
    "#категориальные признаки\n",
    "cat_feautures=['gender',\n",
    "               'first_issue_date_weekday', 'first_issue_date_month',\n",
    "               'first_redeem_date_weekday', 'first_redeem_date_month']\n",
    "\n",
    "\n",
    "CatBoost_space = {\n",
    "    'learning_rate': hp.choice('learning_rate', np.arange(0.05, 0.31, 0.05)),\n",
    "    'max_depth': hp.choice('max_depth', np.arange(2,11, 1,dtype=int)),\n",
    "    'colsample_bylevel': hp.choice('colsample_bylevel', np.arange(0.3, 0.8, 0.1)),\n",
    "    'iterations': hp.choice('iterations', np.arange(20,200, 5, dtype=int)),\n",
    "    'early_stopping_rounds': hp.choice('early_stopping_rounds', np.arange(1,11, 1, dtype=int)),  \n",
    "}\n",
    "\n",
    "LGBM_space = {\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "        'max_depth': hp.randint('max_depth', 2, 11),\n",
    "        'min_child_samples': hp.randint('min_child_samples', 5, 100),\n",
    "        'subsample': hp.uniform('subsample', 0.7, 1),\n",
    "        'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
    "        'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
    "        'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.3, 0.8, 0.1)),\n",
    "        'num_leaves': hp.randint('num_leaves', 6, 50),\n",
    "        'n_estimators': hp.randint('n_estimators', 200, 600),\n",
    "        'boosting_type':  hp.choice('boosting_type', ['gbdt','dart'])\n",
    "}\n",
    "\n",
    "RandomForest_space ={\n",
    "    'n_estimators': hp.randint('n_estimators', 200, 600), \n",
    "    'criterion':hp.choice('criterion',['gini', 'entropy']),\n",
    "    'max_depth': hp.randint('max_depth', 2, 11),\n",
    "    'min_samples_split':hp.randint('min_samples_split', 2, 50), \n",
    "    'min_samples_leaf':hp.randint('min_samples_leaf', 2, 50), \n",
    "    'min_weight_fraction_leaf':hp.uniform('min_weight_fraction_leaf', 0.0, 0.1) \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Функция для вычисления погрешности измерения score модели**\n",
    "<a id='section_id4.4'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:38:23.623749Z",
     "iopub.status.busy": "2023-02-11T13:38:23.623336Z",
     "iopub.status.idle": "2023-02-11T13:38:23.641620Z",
     "shell.execute_reply": "2023-02-11T13:38:23.639947Z",
     "shell.execute_reply.started": "2023-02-11T13:38:23.623712Z"
    }
   },
   "outputs": [],
   "source": [
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    '''\n",
    "    Вычисление среднего значения случайной величины и ее случайной погрешности\n",
    "    :data: - датафрейм измерений величины\n",
    "    :confidence: доверительная вероятность\n",
    "    return: m - среднее, h - погрешность'''\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), sem(a)\n",
    "    h = se * t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Функция для вывода средних значений метрик и их погрешностей при кросс-валидации с текущими параметрами**\n",
    "<a id='section_id4.5'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:38:23.644363Z",
     "iopub.status.busy": "2023-02-11T13:38:23.643903Z",
     "iopub.status.idle": "2023-02-11T13:38:23.669861Z",
     "shell.execute_reply": "2023-02-11T13:38:23.668569Z",
     "shell.execute_reply.started": "2023-02-11T13:38:23.644321Z"
    }
   },
   "outputs": [],
   "source": [
    "CONFIDENCE=0.95 # доверительная вероятность\n",
    "\n",
    "def objective(params, classification_type, model_type, kf, get_score,  X_full, \n",
    "              y_full, treatment_full):\n",
    "    \"\"\"\n",
    "    Кросс-валидация с текущими гиперпараметрами\n",
    "    :params: гиперпараметры\n",
    "    :classification_type: CatBoostClassifier/LGBMClassifier/RandomForestClassifier\n",
    "    :model_type: Solomodel/ClassTransformation/Two models\n",
    "    :kf: KFolds\n",
    "    :get_score: метрика\n",
    "    :X_full: матрица признаков\n",
    "    :y_full: вектор меток объектов\n",
    "    :treatment_full: вектор наличия взаимодействия\n",
    "    :num_folds: число фолдов в кросс-валидации\n",
    "    :return: значение loss-функции, средняя точность и погрешность \n",
    "    для каждой метрики на кросс-валидации\n",
    "    \"\"\" \n",
    "    # выбор модели\n",
    "    if (classification_type == 'CatBoost'):\n",
    "        cur_classification_type = CatBoostClassifier(cat_features=cat_feautures, \n",
    "                                                     random_state=42, \n",
    "                                                     silent=True,**params)\n",
    "    elif (classification_type == 'LGBM'):\n",
    "        cur_classification_type = LGBMClassifier(force_row_wise=True, verbose=-1, \n",
    "                                         random_state=42,**params)\n",
    "    elif (classification_type == 'RandomForest'):\n",
    "        cur_classification_type=RandomForestClassifier(random_state=42, \n",
    "                                                       verbose=0,**params)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    #выбор подхода к решению задачи\n",
    "    if (model_type == 'SoloModel'):\n",
    "        cur_model = SoloModel(estimator=cur_classification_type)\n",
    "    elif (model_type == 'ClassTransformation'):\n",
    "        cur_model=ClassTransformation(estimator=cur_classification_type)\n",
    "    elif (model_type == 'TwoModels_independent'):\n",
    "        cur_model=TwoModels(estimator_trmnt=cur_classification_type, \n",
    "                            estimator_ctrl=clone(cur_classification_type), \n",
    "                            method='vanilla')\n",
    "    elif (model_type == 'TwoModels_dependent'):\n",
    "        cur_model=TwoModels(estimator_trmnt=cur_classification_type, \n",
    "                            estimator_ctrl=clone(cur_classification_type), \n",
    "                            method='ddr_treatment')    \n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    # проводим кросс-валидацию\n",
    "    folds = kf\n",
    "    upl_at_k_scores, upl_auc_scores, upl_qini_scores = [], [], []\n",
    "    #делим на тренировочные и валидационные датасеты\n",
    "    for i, (train_index, valid_index) in enumerate(folds.split(X_full, y_full)):\n",
    "        X_train, X_valid = X_full.iloc[train_index], X_full.iloc[valid_index]\n",
    "        y_train, y_valid = y_full.iloc[train_index], y_full.iloc[valid_index]        \n",
    "        treat_train, treat_valid = treatment_full.iloc[train_index], \\\n",
    "                                                     treatment_full.iloc[valid_index]\n",
    "        #получаем scores для этого фолда\n",
    "        scores = get_scores(cur_model,X_train, X_valid, y_train, y_valid, \n",
    "                                 treat_train, treat_valid)\n",
    "        #заносим результаты в списки\n",
    "        upl_at_k_scores.append(scores['upl_at_k'])\n",
    "        upl_auc_scores.append(scores['upl_auc'])\n",
    "        upl_qini_scores.append(scores['upl_qini'])\n",
    "    \n",
    "    #ищем средние значения и погрешности\n",
    "    mean_upl_at_k_score, delta_upl_at_k_score =\\\n",
    "                      mean_confidence_interval(upl_at_k_scores, confidence=CONFIDENCE)\n",
    "    mean_upl_auc_score, delta_upl_auc_score =\\\n",
    "                      mean_confidence_interval(upl_auc_scores, confidence=CONFIDENCE)\n",
    "    mean_upl_qini_score, delta_upl_qini_score =\\\n",
    "                      mean_confidence_interval(upl_qini_scores, confidence=CONFIDENCE)\n",
    "    \n",
    "    #Значение Loss-функции будет рассчитываться как среднее mean_upl_auc_score с \"-\"\n",
    "    \n",
    "\n",
    "    # возвращаем результаты, которые записываются в Trials()\n",
    "    return   {'loss': -mean_upl_auc_score, \n",
    "              'uplift_auc_score':mean_upl_auc_score, \n",
    "              'delta_uplift_auc_score': delta_upl_auc_score, \n",
    "              'uplift_qini_score':mean_upl_qini_score, \n",
    "              'delta_uplift_qini_score': delta_upl_qini_score,\n",
    "              'uplift_at_k_score':mean_upl_at_k_score, \n",
    "              'delta_uplift_at_k_score': delta_upl_at_k_score,\n",
    "              'params': params, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Функция получения истории поиска оптимальных гиперпараметров для каждого типа модели**\n",
    "<a id='section_id4.6'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:38:23.673614Z",
     "iopub.status.busy": "2023-02-11T13:38:23.671738Z",
     "iopub.status.idle": "2023-02-11T13:38:23.692688Z",
     "shell.execute_reply": "2023-02-11T13:38:23.691204Z",
     "shell.execute_reply.started": "2023-02-11T13:38:23.673516Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_hyperopt_results(max_evals, classification_type,model_type):\n",
    "    '''\n",
    "    получаем на вход:\n",
    "    :classification_type: Catboost/Lgbmmodel...\n",
    "    :model_type: Solomodel/Two models...\n",
    "    :max_evals: количество итераций поиска оптимальных гиперпараметров\n",
    "    :return: trials - результаты истории поиска оптимальных гиперпараметров'''\n",
    "    if (classification_type == 'CatBoost'):\n",
    "        space = CatBoost_space\n",
    "    elif (classification_type == 'LGBM'):\n",
    "        space = LGBM_space\n",
    "    elif (classification_type == 'RandomForest'):\n",
    "        space=RandomForest_space\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    # запускаем hyperopt\n",
    "    trials = Trials()\n",
    "    best = fmin(\n",
    "                fn=partial(objective, \n",
    "                           classification_type = classification_type,\n",
    "                           model_type = model_type,\n",
    "                           kf=kf,\n",
    "                           get_score=get_scores, \n",
    "                           X_full=X_train, \n",
    "                           y_full=y_train, \n",
    "                           treatment_full = treat_train), # функция для оптимизации \n",
    "                space=space, # пространство поиска гиперпараметров  \n",
    "                algo=tpe.suggest, # алгоритм поиска (байесовская оптимизация)\n",
    "                max_evals=max_evals,# число итераций (можно ещё указать и время поиска) \n",
    "                trials=trials, # куда сохранять историю поиска\n",
    "                rstate=np.random.default_rng(42), # random state\n",
    "                show_progressbar=True # progressbar\n",
    "    )\n",
    "    return trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Функция поиска лучших значений метрик вместе с их погрешностями, а также параметров, при которых такие результаты достигаются**\n",
    "<a id='section_id4.7'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:38:23.696061Z",
     "iopub.status.busy": "2023-02-11T13:38:23.695189Z",
     "iopub.status.idle": "2023-02-11T13:38:23.716083Z",
     "shell.execute_reply": "2023-02-11T13:38:23.714875Z",
     "shell.execute_reply.started": "2023-02-11T13:38:23.696007Z"
    }
   },
   "outputs": [],
   "source": [
    "#в таком порядке будут перебираться модели\n",
    "model_types=['SoloModel'] * 3 + ['ClassTransformation'] * 3 + \\\n",
    "    ['TwoModels_independent'] * 3 + ['TwoModels_dependent'] * 3\n",
    "classification_types=['LGBM', 'CatBoost', 'RandomForest'] * 4\n",
    "\n",
    "\n",
    "def find_best_params(trials_results):\n",
    "    '''\n",
    "    Поиск лучших результатов hyperopt в формате\n",
    "    :trials_results: результаты hyperopt (trials.results)\n",
    "    :return: лучший значение score его дисперсия для каждой из трех метрик \n",
    "    и параметры, при которых достигаются лучшие score'''\n",
    "    results = pd.DataFrame([x for x in  trials_results])\n",
    "    \n",
    "    #поиск лучшего uplift_auc_score, его погрешности и параметров, при которых это\n",
    "    #достигается\n",
    "    results.sort_values(by=['uplift_auc_score'], ascending=False, inplace=True)\n",
    "    best_uplift_auc_score=results.iloc[0]['uplift_auc_score']\n",
    "    delta_of_best_uplift_auc_score=results.iloc[0]['delta_uplift_auc_score']\n",
    "    best_params_for_uplift_auc_score=results.iloc[0]['params']\n",
    "    \n",
    "    #то же самое для qini_auc_score\n",
    "    results.sort_values(by=['uplift_qini_score'], ascending=False, inplace=True)\n",
    "    best_uplift_qini_score=results.iloc[0]['uplift_qini_score']\n",
    "    delta_of_best_uplift_qini_score=results.iloc[0]['delta_uplift_qini_score']\n",
    "    best_params_for_uplift_qini_score=results.iloc[0]['params']\n",
    "    \n",
    "    #то же самое для uplift_at_k\n",
    "    results.sort_values(by=['uplift_at_k_score'], ascending=False, inplace=True)\n",
    "    best_uplift_at_k_score=results.iloc[0]['uplift_at_k_score']\n",
    "    delta_of_best_uplift_at_k_score=results.iloc[0]['delta_uplift_at_k_score']\n",
    "    best_params_for_uplift_at_k_score=results.iloc[0]['params']\n",
    "    \n",
    "    return {'best_auc_score': best_uplift_auc_score, \n",
    "            'delta_of_best_auc_score':delta_of_best_uplift_auc_score, \n",
    "            'best_params_for_auc_score': best_params_for_uplift_auc_score,\n",
    "            'best_qini_score': best_uplift_qini_score, \n",
    "            'delta_of_best_qini_score':delta_of_best_uplift_qini_score, \n",
    "            'best_params_for_qini_score': best_params_for_uplift_qini_score,\n",
    "            'best_uplift_at_k_score': best_uplift_at_k_score, \n",
    "            'delta_of_best_uplift_at_k_score':delta_of_best_uplift_at_k_score, \n",
    "            'best_params_for_uplift_at_k_score': best_params_for_uplift_at_k_score}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Функция получения датафрейма со значениями метрик и их погрешностями в зависимости от итерации подбора оптимальных гиперпараметров для заданного типа модели**\n",
    "<a id='section_id4.8'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:38:23.720021Z",
     "iopub.status.busy": "2023-02-11T13:38:23.718041Z",
     "iopub.status.idle": "2023-02-11T13:38:23.738737Z",
     "shell.execute_reply": "2023-02-11T13:38:23.737104Z",
     "shell.execute_reply.started": "2023-02-11T13:38:23.719891Z"
    }
   },
   "outputs": [],
   "source": [
    "def score_history(trials_results, classification_type, model_type):\n",
    "    '''\n",
    "    Получение значений score в зависимости от текущей итерации для каждой метрики\n",
    "    :trials_results: результаты hyperopt (trials.results)\n",
    "    return: pd.Series - значения score и их погрешности для каждй метрики, \n",
    "    индекс - номер итерации (нумерация с 0)\n",
    "    '''\n",
    "    results = pd.DataFrame([x for x in  trials_results])\n",
    "    results.drop(columns=['loss', 'params', 'status'], inplace=True)\n",
    "    \n",
    "    ans=results.add_suffix(f'_for_{model_type}_with_{classification_type}') \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Функция получения двух датафреймов с результатами подбора гиперпараметров**\n",
    "<a id='section_id4.9'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:38:23.741443Z",
     "iopub.status.busy": "2023-02-11T13:38:23.740282Z",
     "iopub.status.idle": "2023-02-11T13:38:23.755944Z",
     "shell.execute_reply": "2023-02-11T13:38:23.754474Z",
     "shell.execute_reply.started": "2023-02-11T13:38:23.741400Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_best_results_and_history(max_evals, model_types, classification_types):\n",
    "    '''\n",
    "    Получение двух таблиц: первая - best score и погрешность (для каждой метрики) \n",
    "    для каждой модели,\n",
    "    вторая - зависимость score (с погрешностями) для каждой метрики от номера итерации\n",
    "    :max_evals: количество итераций\n",
    "    :model_types: список последовательности используемых подходов (SoloModel/...)\n",
    "    :classification_types: список последовательности классификаторов (LGBM/...)\n",
    "    '''\n",
    "    #Таблица результатов score с каждой итерацией\n",
    "    history_of_scores = pd.DataFrame(index=range(0,max_evals), \n",
    "                                     columns=['iteration'], \n",
    "                                     data=range(1,max_evals+1))\n",
    "    \n",
    "    # Таблица лучших результатов для каждой модели\n",
    "    best_results = pd.DataFrame(columns=['model_type','classification_type',\n",
    "                                         'best_auc_score','delta_of_best_auc_score',\n",
    "                                         'best_params_for_auc_score',\n",
    "                                         'best_qini_score','delta_of_best_qini_score',\n",
    "                                         'best_params_for_qini_score',\n",
    "                                         'best_uplift_at_k_score',\n",
    "                                         'delta_of_best_uplift_at_k_score',\n",
    "                                         'best_params_for_uplift_at_k_score'])\n",
    "    \n",
    "    for i in range(len(model_types)): #по сути это 12 - число различных моделей\n",
    "        trials=find_hyperopt_results(max_evals, classification_types[i],model_types[i])\n",
    "        best_scores_params=find_best_params(trials.results)\n",
    "        #заполнение новой строчки таблицы с лучшими результатами\n",
    "        best_results.loc[len(best_results.index)] = \\\n",
    "            [model_types[i], classification_types[i]] +list(best_scores_params.values())\n",
    "        #Заполнение новых столбцов таблицы history_of_scores\n",
    "        new_cols=score_history(trials.results, classification_types[i], model_types[i])\n",
    "        history_of_scores = pd.concat([history_of_scores, new_cols], axis=1, \n",
    "                                      join='inner')\n",
    "        \n",
    "    return best_results, history_of_scores        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Получение датафреймов с результатами подбора гиперпараметров**\n",
    "<a id='section_id4.10'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:38:23.758329Z",
     "iopub.status.busy": "2023-02-11T13:38:23.757796Z",
     "iopub.status.idle": "2023-02-11T13:38:23.773931Z",
     "shell.execute_reply": "2023-02-11T13:38:23.772857Z",
     "shell.execute_reply.started": "2023-02-11T13:38:23.758288Z"
    }
   },
   "outputs": [],
   "source": [
    "# NUM_ITERATIONS=20  #число итераций подбора гиперпараметров\n",
    "\n",
    "# best_results, history_of_scores=get_best_results_and_history(NUM_ITERATIONS, \n",
    "#                                                              model_types,\n",
    "#                                                              classification_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получение таблиц `best_results` и `history_of_scores` занимает очень много времени: например при 20 итерациях это процесс занял порядка 10 часов, поэтому результаты выполнения функции get_best_results_and_history(20, model_types, classification_types) были сохранены и заново загружены в ноутбук, чтобы в дальнейшем не вызывать функцию вновь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:38:23.775770Z",
     "iopub.status.busy": "2023-02-11T13:38:23.775127Z",
     "iopub.status.idle": "2023-02-11T13:38:23.813647Z",
     "shell.execute_reply": "2023-02-11T13:38:23.812658Z",
     "shell.execute_reply.started": "2023-02-11T13:38:23.775734Z"
    }
   },
   "outputs": [],
   "source": [
    "# #Сохранение\n",
    "# best_results.to_csv('best_results_for_20_iter.csv',index=False)\n",
    "# history_of_scores.to_csv('history_of_scores_for_20_iter.csv',index=False)\n",
    "\n",
    "\n",
    "#загрузка таблиц best_results и history_of_scores\n",
    "best_results = pd.read_csv('/kaggle/input/best-results-and-history-of-score-20-iters/best_results_for_20_iter.csv')\n",
    "history_of_scores = pd.read_csv('/kaggle/input/best-results-and-history-of-score-20-iters/history_of_scores_for_20_iter.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:38:23.815846Z",
     "iopub.status.busy": "2023-02-11T13:38:23.815444Z",
     "iopub.status.idle": "2023-02-11T13:38:23.835573Z",
     "shell.execute_reply": "2023-02-11T13:38:23.834296Z",
     "shell.execute_reply.started": "2023-02-11T13:38:23.815810Z"
    }
   },
   "outputs": [],
   "source": [
    "best_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:38:23.837489Z",
     "iopub.status.busy": "2023-02-11T13:38:23.837114Z",
     "iopub.status.idle": "2023-02-11T13:38:23.871432Z",
     "shell.execute_reply": "2023-02-11T13:38:23.870029Z",
     "shell.execute_reply.started": "2023-02-11T13:38:23.837453Z"
    }
   },
   "outputs": [],
   "source": [
    "history_of_scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Функция отображения графика зависимости метрики от итерации (с возможностью построения планок погрешностей)**\n",
    "<a id='section_id4.11'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:38:23.873455Z",
     "iopub.status.busy": "2023-02-11T13:38:23.873049Z",
     "iopub.status.idle": "2023-02-11T13:38:23.887460Z",
     "shell.execute_reply": "2023-02-11T13:38:23.886102Z",
     "shell.execute_reply.started": "2023-02-11T13:38:23.873419Z"
    }
   },
   "outputs": [],
   "source": [
    "def draw_res(metrics_type, style, ax, results, model_types, \n",
    "             classification_types, plot_errors=False):\n",
    "    '''\n",
    "    Отрисовка зависимости Score от итерации для какой-то одной метрики для всех\n",
    "    типов моделей\n",
    "    :metrics_type: 'auc', 'qini', 'at_k' - тип исследуемой метрики\n",
    "    :style: 'lineplot', 'scatterplot' - тип графика\n",
    "    :ax: - где рисовать, на какой фигуре\n",
    "    :results: из какой таблицы брать данные (history_of_scores)\n",
    "    :model_types: Solomodel/...\n",
    "    :classification_types: LGBM/...\n",
    "    '''\n",
    "    y_col=f'uplift_{metrics_type}_score_for_{model_types}_with_{classification_types}'\n",
    "\n",
    "    if (style=='lineplot'):\n",
    "        sns.lineplot(ax=ax, x='iteration',\n",
    "                     y=y_col, \n",
    "                     data=results, \n",
    "                     label=f'{model_types}_{classification_types}') \n",
    "\n",
    "    elif (style=='scatterplot'):\n",
    "        sns.scatterplot(ax=ax, x='iteration',\n",
    "                        y=y_col, \n",
    "                     data=results, s=50, \n",
    "                     label=f'{model_types}_{classification_types}')\n",
    "    \n",
    "    if plot_errors:\n",
    "        ax.errorbar(results['iteration'],results[y_col], \n",
    "                     yerr = results['delta_'+y_col], fmt =\"o\") #погрешности\n",
    "\n",
    "\n",
    "    ax.set(xlabel='Iteration', ylabel=f'uplift_{metrics_type}_score')\n",
    "    ax.set_title(f'Зависимость uplift_{metrics_type}_score от итерации',\n",
    "                               fontweight='bold')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Отображение зависимостей метрик от итерации подбора гиперпараметров**\n",
    "<a id='section_id4.12'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:38:23.889369Z",
     "iopub.status.busy": "2023-02-11T13:38:23.888981Z",
     "iopub.status.idle": "2023-02-11T13:38:25.988842Z",
     "shell.execute_reply": "2023-02-11T13:38:25.987403Z",
     "shell.execute_reply.started": "2023-02-11T13:38:23.889328Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "NUM_CURVES = 12 #количество различных моделей (4 модели * 3 классификатора)\n",
    "NUM_METRICS = 3 #количество рассматриваемых метрик\n",
    "METRICS = ['auc', 'qini', 'at_k'] #рассматриваемые метрики\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15,NUM_METRICS*5))\n",
    "for num_metric in range(NUM_METRICS):\n",
    "    for i in range(NUM_CURVES):\n",
    "        draw_res(METRICS[num_metric],'lineplot',axes[num_metric], history_of_scores, \n",
    "                 model_types[i], classification_types[i])\n",
    "    axes[num_metric].legend(bbox_to_anchor=(1.35, 0.95), frameon=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Также имеется возможность построить те же графики, но в формате диаграммы рассеяния"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Анализируя графики можно прийти к выводу о том, что зависимости `uplift_auc_score` и `qini_auc_score` пропорциональны друг другу (это интуитивно было понятно, но наглядно убедился в этом). Также можно заметить, что стабильно высокие значения метрик получаются в модели ClassTransformation + RandomForest, а также что Solomodel + RandomForest в паре выдают слабый результат. Построим далее гистограммы лучших значений метрик (с погрешностями) для каждой модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Функция построения гистограмм с погрешностями**\n",
    "<a id='section_id4.13'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:38:25.990773Z",
     "iopub.status.busy": "2023-02-11T13:38:25.990395Z",
     "iopub.status.idle": "2023-02-11T13:38:26.003146Z",
     "shell.execute_reply": "2023-02-11T13:38:26.001813Z",
     "shell.execute_reply.started": "2023-02-11T13:38:25.990739Z"
    }
   },
   "outputs": [],
   "source": [
    "def grouped_barplot(ax, df, category_col,subcategory_col, val , err):\n",
    "    '''\n",
    "    Построение barplot с погрешностями\n",
    "    :df: таблица, в которой есть столбцы: категория (model_type), \n",
    "    подкатегория (classification_type), value (best_score), \n",
    "    err (погрешность best_score)\n",
    "    :category_col: колонка-категория таблицы df\n",
    "    :subcategory_col: колонка-подкатегория таблицы df\n",
    "    :val: колонка-значения таблицы df\n",
    "    :err: колонка-погрешности таблицы df\n",
    "    '''\n",
    "    #список категорий (Solomodel, ...)\n",
    "    categories_unique = df[category_col].unique() \n",
    "    \n",
    "    #индекс категории (0,1,..., n)\n",
    "    category_index = np.arange(len(categories_unique)) \n",
    "    \n",
    "    #список подкатегорий (LGBM,...)\n",
    "    subcategories_unique = df[subcategory_col].unique() \n",
    "    \n",
    "    #смещение относительно координаты центра категории\n",
    "    offsets = (np.arange(len(subcategories_unique))-np.arange(len(subcategories_unique)).mean())/(len(subcategories_unique)+1.)\n",
    "    #ширина столбца\n",
    "    width= np.diff(offsets).mean()\n",
    "    for i,cur_subcat in enumerate(subcategories_unique):\n",
    "        #таблица из строк, относящихся к текущей подкатегории\n",
    "        df_cur_subcat = df[df[subcategory_col] == cur_subcat]\n",
    "        ax.bar(category_index+offsets[i], df_cur_subcat[val].values, width=width, \n",
    "                label=f'{cur_subcat}', yerr=df_cur_subcat[err].values)\n",
    "    ax.set(xlabel=category_col, ylabel=val,  xticks=category_index, \n",
    "           xticklabels=categories_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Функция добавления в гистограмму лейблов для каждого столбца**\n",
    "<a id='section_id4.14'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:38:26.005249Z",
     "iopub.status.busy": "2023-02-11T13:38:26.004783Z",
     "iopub.status.idle": "2023-02-11T13:38:26.021393Z",
     "shell.execute_reply": "2023-02-11T13:38:26.020452Z",
     "shell.execute_reply.started": "2023-02-11T13:38:26.005211Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_value_labels(ax, spacing=0, where='center', angle=90):\n",
    "    \"\"\"Добавление лейблов для каждого столбца barplot'а\n",
    "    Аргументы:\n",
    "    ax (matplotlib.axes.Axes): matplotlib object содержащий axes графика\n",
    "    spacing (int): Расстояние между лейблами и столбцами\n",
    "    where: куда поместить надпись (bottom/center/top)\n",
    "    angle: угол поворота надписи (0 - горизонталь, 90 - снизу вверх)\n",
    "    \"\"\"\n",
    "    # Для каждого столбца:  размещение лейбла\n",
    "    for rect in ax.patches:\n",
    "        # Получение X и Y позиции лейбла\n",
    "        if (where =='center'):\n",
    "            y_value = rect.get_height()/2\n",
    "        elif (where == 'top'):\n",
    "            y_value = rect.get_height()\n",
    "        elif (where == 'bottom'):\n",
    "            y_value = rect.get_height()/10\n",
    "        x_value = rect.get_x() + rect.get_width() / 2\n",
    "\n",
    "        space = spacing #кол-во точек между столбцом и лейблом\n",
    "        va = 'bottom' # такое выравнивание для положительных чисел\n",
    "\n",
    "        if y_value < 0:\n",
    "            space *= -1 # перевернем пространство, чтобы расположить лейбл\n",
    "            va = 'top' # размещение лейбла под столбцом\n",
    "\n",
    "        # Значение Y - это лейбл, формат 4 знака после запятой\n",
    "        label = \"{:.4f}\".format(rect.get_height()) \n",
    "\n",
    "        # Создание комментария\n",
    "        text =ax.annotate(\n",
    "            label,                      # применяем `label` как label\n",
    "            (x_value, y_value),         # местоположение\n",
    "            xytext=(0, space),          # Вертикальный отступ лейбла от столбца \n",
    "            textcoords=\"offset points\", # интерпретируем так`xytext` \n",
    "            ha='center',                # Центрирование по горизонтали лейбла \n",
    "            va=va)                      # Vertically align (va) - top/bottom\n",
    "        text.set_rotation(angle)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Построение гистограмм с погрешностями для каждой метрики для каждого типа модели**\n",
    "<a id='section_id4.15'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:38:26.023777Z",
     "iopub.status.busy": "2023-02-11T13:38:26.023312Z",
     "iopub.status.idle": "2023-02-11T13:38:27.179869Z",
     "shell.execute_reply": "2023-02-11T13:38:27.178310Z",
     "shell.execute_reply.started": "2023-02-11T13:38:26.023739Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(NUM_METRICS, 1, figsize=(10,NUM_METRICS*5))\n",
    "for num_metric in range(NUM_METRICS):\n",
    "    if METRICS[num_metric]!='at_k':\n",
    "        y_col=f'best_{METRICS[num_metric]}_score'\n",
    "    elif METRICS[num_metric]=='at_k':  \n",
    "        y_col=f'best_uplift_{METRICS[num_metric]}_score'\n",
    "    delta_y_col='delta_of_'+y_col\n",
    "    grouped_barplot(axes[num_metric], best_results, 'model_type', 'classification_type',\n",
    "                    y_col, delta_y_col)\n",
    "    axes[num_metric].legend(bbox_to_anchor=(1.22, 0.95), title='Классификатор',\n",
    "                            frameon=True)\n",
    "    y_col_for_title=y_col.replace('best_', '')\n",
    "    axes[num_metric].set_title(f'Значение {y_col_for_title} для лучшей модели',\n",
    "                               fontweight='bold') \n",
    "    add_value_labels(axes[num_metric], where='bottom')\n",
    "    \n",
    "plt.tight_layout()   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что модель типа `две зависимые модели` выдает плохие результаты при любом из рассматриваемом классификаторе ,в то время как модель `трансформация классов` ведет себя наилучшим образом с любым классификатором. Стоит заметить, что лучшее значение `auc_score` (`qini_score`) достигается с моделью `ClassTransformation + LGBMClassifier`, а лучшее значение `uplift_at_30%` достигается с моделью `ClassTransformation + RandomForest`. \n",
    "\n",
    "Думаю, что нужно для моделей, показавших лучшие значения метрик, попробовать еще раз поподбирать оптимальные гиперпараметры, но уже на большем количестве итераций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Работа с типом модели, показавшим лучшее значение метрики \n",
    "<a id='section_id5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Функция получения связки модель + классификатор, для которых лучшее значение метрики**\n",
    "<a id='section_id5.1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:38:27.182237Z",
     "iopub.status.busy": "2023-02-11T13:38:27.181743Z",
     "iopub.status.idle": "2023-02-11T13:38:27.190639Z",
     "shell.execute_reply": "2023-02-11T13:38:27.189239Z",
     "shell.execute_reply.started": "2023-02-11T13:38:27.182186Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_best_model(type_best, best_results):\n",
    "    '''\n",
    "    :type_best: по какой метрике ищем лучшую модель\n",
    "    :best_results: таблица со значениями best_score (для каждой метрики) для каждой \n",
    "    модели\n",
    "    return: тип модели, классификатор, для которых score наилучший\n",
    "    '''\n",
    "    best_results.sort_values(by=[f'best_{type_best}_score'], ascending=False, inplace=True)\n",
    "    \n",
    "    #строчка в таблице, откуда считываем нужную информацию\n",
    "    best_line= best_results.iloc[0]\n",
    "    \n",
    "    best_model_type, best_classification_type = \\\n",
    "                            best_line.model_type, best_line.classification_type\n",
    "    print(f'Лучшая модель: {best_model_type} с классификатором {best_classification_type}')\n",
    "    return best_model_type, best_classification_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Функция вывода на экран лучшего значения метрики с погрешностью**\n",
    "<a id='section_id5.2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:38:27.193104Z",
     "iopub.status.busy": "2023-02-11T13:38:27.192579Z",
     "iopub.status.idle": "2023-02-11T13:38:27.205060Z",
     "shell.execute_reply": "2023-02-11T13:38:27.203710Z",
     "shell.execute_reply.started": "2023-02-11T13:38:27.193054Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_best_score(metric, best_results_for_best_model):\n",
    "    '''Вывести значение метрики и ее погрешность для лучшей модели'''\n",
    "    score_col_name=f'best_{metric}_score' #имя столбца, где значение score\n",
    "    delta_col_name='delta_of_'+score_col_name\n",
    "    best_score, delta_of_best=best_results_for_best_model.iloc[0][score_col_name], \\\n",
    "                        best_results_for_best_model.iloc[0][delta_col_name]\n",
    "    print(f'Best_{metric}_score: {best_score}')\n",
    "    print(f'delta_of_best_{metric}_score: {delta_of_best}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Функция отображения результатов для лучшей модели относительно данной метрики**\n",
    "<a id='section_id5.3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:38:27.208146Z",
     "iopub.status.busy": "2023-02-11T13:38:27.207403Z",
     "iopub.status.idle": "2023-02-11T13:38:27.226460Z",
     "shell.execute_reply": "2023-02-11T13:38:27.224778Z",
     "shell.execute_reply.started": "2023-02-11T13:38:27.208087Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_results_for_best_model(type_best, num_iter_control):\n",
    "    '''\n",
    "    Поиск лучшей связки модель + классификатор для данной метрики, \n",
    "    Поиск оптимальных параметров на бОльшем количестве итераций,\n",
    "    Построение графиков зависимости метрик от итерации подбора гиперпараметров,\n",
    "    Вывод лучших значений метрик с погрешностями\n",
    "    :type_best: 'auc'/ 'qini'/ 'uplift_at_k' - метрика, относительно которой \n",
    "    ищется лучшая связка модель + классификатор\n",
    "    :num_iter_control: количество итераций подбора гиперпараметров\n",
    "    :return: оптимальные гиперпараметры, тип модели и классификатора\n",
    "    '''\n",
    "    #получение связки модель + классификатор для данной метрики\n",
    "    best_model_type, best_classification_type=\\\n",
    "                                     find_best_model(type_best, best_results)\n",
    "    \n",
    "    #таблицы результатов для данной модели\n",
    "    best_results_for_best_model, history_of_scores_for_best_model=\\\n",
    "         get_best_results_and_history(num_iter_control, [best_model_type], \n",
    "                                      [best_classification_type])\n",
    "    \n",
    "    #графики зависимости значений метрики от итерации\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(15,NUM_METRICS*5))\n",
    "    for num_metric in range(NUM_METRICS):\n",
    "        draw_res(METRICS[num_metric], 'lineplot',axes[num_metric], \n",
    "                 history_of_scores_for_best_model, best_model_type, \n",
    "                 best_classification_type, plot_errors=True)\n",
    "        axes[num_metric].legend(bbox_to_anchor=(1.25, 0.95), frameon=True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    #получение лучших параметров для лучшей пары модель+классификатор\n",
    "    params_best=f'best_params_for_{type_best}_score'\n",
    "    best_params_for_best_model=best_results_for_best_model.iloc[0][params_best]\n",
    "    \n",
    "    #отображение значений метрик и их погрешностей\n",
    "    print(f'Для модели с лучшим значением метрики {type_best} имеем:')\n",
    "    print_best_score('auc',best_results_for_best_model)\n",
    "    print_best_score('qini', best_results_for_best_model)\n",
    "    print_best_score('uplift_at_k', best_results_for_best_model)\n",
    "    \n",
    "    return best_params_for_best_model, best_model_type, best_classification_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Получение результатов для лучшей модели относительно данной метрики**\n",
    "<a id='section_id5.4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Относительно метрики `uplift_auc_score`\n",
    "<a id='section_id5.4a'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T13:38:27.229386Z",
     "iopub.status.busy": "2023-02-11T13:38:27.228969Z",
     "iopub.status.idle": "2023-02-11T15:15:21.374240Z",
     "shell.execute_reply": "2023-02-11T15:15:21.373060Z",
     "shell.execute_reply.started": "2023-02-11T13:38:27.229347Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "NUM_ITERS_CONTROL=50\n",
    "best_params_for_auc_best_model, best_auc_model_type, best_auc_classification_type =\\\n",
    "        get_results_for_best_model(type_best='auc', num_iter_control=NUM_ITERS_CONTROL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Относительно метрики `uplift_at_30%`\n",
    "<a id='section_id5.4b'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T15:15:21.376655Z",
     "iopub.status.busy": "2023-02-11T15:15:21.376169Z",
     "iopub.status.idle": "2023-02-11T21:03:01.221091Z",
     "shell.execute_reply": "2023-02-11T21:03:01.219615Z",
     "shell.execute_reply.started": "2023-02-11T15:15:21.376607Z"
    }
   },
   "outputs": [],
   "source": [
    "best_params_for_uplift_at_k_best_model, best_uplift_at_k_model_type, \\\n",
    "                                best_uplift_at_k_classification_type =\\\n",
    "            get_results_for_best_model(type_best='uplift_at_k', \n",
    "                                       num_iter_control=NUM_ITERS_CONTROL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предсказания лучших моделей на тестовой выборке\n",
    "<a id='section_id6'></a>\n",
    "\n",
    "В постановке задачи указано, что необходимо пометить 1 тех клиентов, которым стоит отправлять СМС, к значению аплифта для каждого клиента прибавим 0.5. Таким образом при положительном значении аплифта клиент будет помечен 1, а при отрицательном 0.\n",
    "\n",
    "Для этого создается лучшая связка модель+классификатор с лучшими гиперпараметрами, которая обучается на тренировочном датасете, а затем дает предсказания на тестовых данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Функция создания модели с оптимальными значениями гиперпараметров**\n",
    "<a id='section_id6.1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T21:06:25.567718Z",
     "iopub.status.busy": "2023-02-11T21:06:25.567149Z",
     "iopub.status.idle": "2023-02-11T21:06:25.581291Z",
     "shell.execute_reply": "2023-02-11T21:06:25.579717Z",
     "shell.execute_reply.started": "2023-02-11T21:06:25.567663Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_final_model(params, classification_type, model_type):\n",
    "    \"\"\"\n",
    "    Создание лучшей пары модель+классификатор\n",
    "    :params: гиперпараметры\n",
    "    :classification_type: CatBoostClassifier/LGBMClassifier/RandomForestClassifier\n",
    "    :model_type: Solomodel/ClassTransformation/Two models\n",
    "    :return: model (модель)\n",
    "    \"\"\" \n",
    "    # выбор модели\n",
    "    if (classification_type == 'CatBoost'):\n",
    "        cur_classification_type = CatBoostClassifier(cat_features=cat_feautures, \n",
    "                                                     random_state=42, \n",
    "                                                     silent=True,**params)\n",
    "    elif (classification_type == 'LGBM'):\n",
    "        cur_classification_type = LGBMClassifier(force_row_wise=True, verbose=-1, \n",
    "                                         random_state=42,**params)\n",
    "    elif (classification_type == 'RandomForest'):\n",
    "        cur_classification_type=RandomForestClassifier(random_state=42, verbose=0,\n",
    "                                                       **params)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    #выбор подхода к решению задачи\n",
    "    if (model_type == 'SoloModel'):\n",
    "        model = SoloModel(estimator=cur_classification_type)\n",
    "    elif (model_type == 'ClassTransformation'):\n",
    "        model=ClassTransformation(estimator=cur_classification_type)\n",
    "    elif (model_type == 'TwoModels_independent'):\n",
    "        model=TwoModels(estimator_trmnt=cur_classification_type, \n",
    "                            estimator_ctrl=clone(cur_classification_type), \n",
    "                            method='vanilla')\n",
    "    elif (model_type == 'TwoModels_dependent'):\n",
    "        model=TwoModels(estimator_trmnt=cur_classification_type, \n",
    "                            estimator_ctrl=clone(cur_classification_type), \n",
    "                            method='ddr_treatment')    \n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Функция получения предсказаний модели с оптимальными гиперпараметрами**\n",
    "<a id='section_id6.2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T21:06:27.692463Z",
     "iopub.status.busy": "2023-02-11T21:06:27.692044Z",
     "iopub.status.idle": "2023-02-11T21:06:27.704087Z",
     "shell.execute_reply": "2023-02-11T21:06:27.702767Z",
     "shell.execute_reply.started": "2023-02-11T21:06:27.692429Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_preds(type_best):\n",
    "    '''\n",
    "    Создание лучшей модели с оптимальными гиперпараметрами для метрики,\n",
    "    получение предсказаний для тестовой выборки,\n",
    "    построение графика распределения предсказаний,\n",
    "    построение графика важности признаков\n",
    "    :type_best: метрика, отн которой берется лучшая модель ('auc', 'uplift_at_k')\n",
    "    :return: датафрейм предсказаний \n",
    "    '''\n",
    "    #создание модели\n",
    "    if (type_best == 'auc'):\n",
    "        my_model=get_final_model(best_params_for_auc_best_model, \n",
    "                                 best_auc_classification_type, \n",
    "                                 best_auc_model_type)   \n",
    "    elif (type_best == 'uplift_at_k'):  \n",
    "        my_model=get_final_model(best_params_for_uplift_at_k_best_model, \n",
    "                                 best_uplift_at_k_classification_type, \n",
    "                                 best_uplift_at_k_model_type)\n",
    "        \n",
    "    #обучение модели\n",
    "    my_model=my_model.fit(X_train, y_train, treat_train)\n",
    "    # Получаем uplift для каждого клиента\n",
    "    test_X['uplift'] = my_model.predict(test_X)\n",
    "    # Получаем вероятность посылать или нет СМС\n",
    "    test_X['pred'] = test_X['uplift'] + 0.5\n",
    "    my_predictions=test_X[['pred']]\n",
    "    test_X.drop(columns=['pred', 'uplift'], inplace=True)\n",
    "    \n",
    "    # Построение графика важности признаков\n",
    "    effective_score = pd.DataFrame(data={'score': my_model.estimator.feature_importances_}, \n",
    "                            index=X_train.columns).sort_values(by='score',ascending=False)\n",
    "    fig, ax = plt.subplots(figsize=(10,40))\n",
    "    sns.barplot(ax=ax, data=effective_score, x='score', y=effective_score.index)\n",
    "    ax.set(xlabel='Score', ylabel='Feature', \n",
    "           title=f'Важности признаков для модели с лучшим {type_best}_score')\n",
    "    plt.show()\n",
    "    \n",
    "    return my_predictions\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказания для лучшей модели относительно `uplift_auc_score`\n",
    "<a id='section_id6.2a'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T21:05:22.884490Z",
     "iopub.status.busy": "2023-02-11T21:05:22.884006Z",
     "iopub.status.idle": "2023-02-11T21:06:14.228183Z",
     "shell.execute_reply": "2023-02-11T21:06:14.226944Z",
     "shell.execute_reply.started": "2023-02-11T21:05:22.884452Z"
    }
   },
   "outputs": [],
   "source": [
    "my_predictions_auc_model=get_preds('auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказания для лучшей модели относительно `uplift_at_k`\n",
    "<a id='section_id6.2b'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T21:06:38.109269Z",
     "iopub.status.busy": "2023-02-11T21:06:38.108813Z",
     "iopub.status.idle": "2023-02-11T21:07:59.599871Z",
     "shell.execute_reply": "2023-02-11T21:07:59.598548Z",
     "shell.execute_reply.started": "2023-02-11T21:06:38.109231Z"
    }
   },
   "outputs": [],
   "source": [
    "my_predictions_uplift_at_k_model=get_preds('uplift_at_k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Функция отображения распределения предсказаний для модели**\n",
    "<a id='section_id6.3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T21:08:44.973142Z",
     "iopub.status.busy": "2023-02-11T21:08:44.972732Z",
     "iopub.status.idle": "2023-02-11T21:08:44.982052Z",
     "shell.execute_reply": "2023-02-11T21:08:44.980572Z",
     "shell.execute_reply.started": "2023-02-11T21:08:44.973107Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_preds(ax, type_best, my_predictions):\n",
    "    title_label='Распределение предсказаний для модели с лучшим '\n",
    "    if (type_best=='uplift_at_k'):\n",
    "        title_label=title_label+type_best+'_score'\n",
    "    elif (type_best=='auc'):\n",
    "        title_label=f'{title_label} uplift_{type_best}_score'\n",
    "    sns.histplot(ax=ax, x='pred', data=my_predictions)\n",
    "    ax.set(xlabel='prediction', ylabel='amount')\n",
    "    ax.set_title(label=title_label, \n",
    "             fontweight='bold') \n",
    "    ax.vlines(x = 0.5, ymin = 0, ymax = 2000,\n",
    "           colors = 'red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Распределения предсказаний для модели с лучшим `uplift_auc_score` и `uplift_at_k_score`**\n",
    "<a id='section_id6.4'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T21:08:49.701784Z",
     "iopub.status.busy": "2023-02-11T21:08:49.700516Z",
     "iopub.status.idle": "2023-02-11T21:08:51.931437Z",
     "shell.execute_reply": "2023-02-11T21:08:51.930125Z",
     "shell.execute_reply.started": "2023-02-11T21:08:49.701739Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,1,figsize=(10,10))\n",
    "plot_preds(axes[0], 'auc', my_predictions_auc_model)\n",
    "plot_preds(axes[1], 'uplift_at_k', my_predictions_uplift_at_k_model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что предсказания лучшей в плане метрики uplift_at_30% модели более сдвинуты\n",
    "вправо относительно вертикальной границы классов, т.е. эта модель относит бОльшее количество клиентов к классу 1 (где `treatment_flg` == `purchased`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Выводы**\n",
    "<a id='section_id7'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Была поставлена задача определить перечень клиентов, которым необходимо разослать СМС с целью побудить их к покупке в магазине. Для этого необходимо было определить величину uplift для каждого клиента, и тем у кого эта величина окажется положительная - отправить СМС. Задача решалась в несколько этапов:\n",
    "\n",
    "**1.** На первом этапе была выполнена загрузка данных и их первичный анализ. Были выявлены проблемные вопросы в данных и обозначены пути их решения. Анализ данных показал, что мы имеем дело с данными о клиентах магазина, товарах и совершаемых покупках. Также, в наборе данных имелись данные о воздействии на покупателей и реакции на неё среди клиентов входящих в тренировочную выборку.\n",
    "\n",
    "**2.** Далее, была произведёна предобработка данных, извлечение признаков, удаление лишних признаков и подготовка выборок к обучению моделей. В ходе предобработки были устранены выявленные на первом этапе проблемы в данных - пропуски и недостоверные данные.  По результатам преобразования данных был получен итоговый набор данных состоящий из более 80 признаков. \n",
    "\n",
    "**3.** На третьем этапе был произведен выбор подхода к определению аплифта и выбор оптимальной модели машинного обучения. Наибольшее значение аплифта удалось получить с помощью подхода с трансформацией классой. В данном подходе целевая переменная, которая, по сути, была представлена в виде двух колонок (факт взаимодействия с клиентом и факт совершения покупки) преобразуется в один признак по принципу логического \"И\". Сложность выбора модели и подбора гиперпараметров заключалась в том, что значение аплифта было очень небольшим (не больше 0.1), а от этого данные сильно \"шумели\", приходилось долго подбирать оптимальные гиперпараметры с помощью библиотеки `hyperopt`. \n",
    "\n",
    "**4.** Тестирование финальных моделей показало показало следующие метрики качества: \n",
    "uplift_at_30% = 0.082 +- 0.010, uplift_auc_score: 0.035+- 0.006, \n",
    "uplift_qini_score: 0.024 +- 0.004 (в случае с моделью `ClassTransformation + RandomForest`) и uplift_at_30% = 0.082 +- 0.006, uplift_auc_score: 0.036 +- 0.005,\n",
    "uplift_qini_score: 0.025 +- 0.003 (в случае с моделью `ClassTransformation + LGBMClassifier`). Видно, что во втором случае погрешности меньше, что логично, ведь первая модель с большей уверенностью относит клиентов к тому или иному классу (т.е. вероятность для каждого клиента в первой модели больше отличается от граничного значения 0.5 - граница классов). Стоит также заметить, что подбор оптимальных параметров для моделей с классификатором `CatBoost` происходил значительно быстрее, чем в других случаях. Поэтому если встает вопрос исследовать наиболее подробно пространство гиперпараметров, то лучше, наверное, использовать этот классификатор (его scores было совсем чуть-чуть хуже, чем у модели ClassTranformation с LGBM классификатором). \n",
    "\n",
    "**$4^*.$** Анализ важности признаков показал, что самыми важными признаками являются дата первого использования бонусных баллов, разность времен между датой первого использования бонусных баллов и датой первой покупки, возраст клиентов, средняя сумма покупки клиентов и другие.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
